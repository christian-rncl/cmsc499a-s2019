{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "from fastaiv07.learner import *\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make random data for testing\n",
    "'''\n",
    "def make_colab_data(n, m, max_mIJ = 5):\n",
    "    ratings = np.random.randint(max_mIJ, size=(n,m))\n",
    "    \n",
    "    data_dict = {'row':[], 'col':[], 'm_IJ':[]}\n",
    "    \n",
    "    for row in range(n):\n",
    "        for col in range(m):\n",
    "            data_dict['row'].append(row)\n",
    "            data_dict['col'].append(col)\n",
    "            data_dict['m_IJ'].append(ratings[row,col])\n",
    "    \n",
    "    return pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestData(data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        nonzero_entries = df.loc[df['m_IJ'] > 0].values\n",
    "        self.index_pairs = []\n",
    "        self.vals = []\n",
    "        \n",
    "        for row in nonzero_entries:\n",
    "            self.index_pairs.append((row[0], row[1]))\n",
    "            self.vals.append(float(row[2]))\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.vals)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self.index_pairs[index]\n",
    "        y = self.vals[index]\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDot(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors=3):\n",
    "        super().__init__()\n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        self.u.weight.data.uniform_(0,0.05)\n",
    "        self.m.weight.data.uniform_(0,0.05)\n",
    "        \n",
    "    def forward(self, indices):\n",
    "        row,col = indices[0],indices[1]\n",
    "        u,m = self.u(Variable(row)),self.m(Variable(col))\n",
    "        return (u*m).sum(1).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb(ni,nf):\n",
    "    e = nn.Embedding(ni, nf)\n",
    "    e.weight.data.uniform_(-0.01,0.01)\n",
    "    return e\n",
    "\n",
    "class EmbeddingDotBias(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors=10):\n",
    "        super().__init__()\n",
    "        (self.u, self.m, self.ub, self.mb) = [get_emb(*o) for o in [\n",
    "            (n_users, n_factors), (n_movies, n_factors), (n_users,1), (n_movies,1)\n",
    "        ]]\n",
    "        \n",
    "    def forward(self, indices):\n",
    "        users,movies = indices[0],indices[1]\n",
    "        um = (self.u(users)* self.m(movies)).sum(1)\n",
    "        res = um + self.ub(users).squeeze() + self.mb(movies).squeeze()\n",
    "        return res.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors=15, nh=10, p1=0.05, p2=0.5):\n",
    "        super().__init__()\n",
    "        (self.u, self.m) = [get_emb(*o) for o in [\n",
    "            (n_users, n_factors), (n_movies, n_factors)]]\n",
    "        self.lin1 = nn.Linear(n_factors*2, nh)\n",
    "        self.lin2 = nn.Linear(nh, 1)\n",
    "        self.drop1 = nn.Dropout(p1)\n",
    "        self.drop2 = nn.Dropout(p2)\n",
    "        \n",
    "    def forward(self, indices):\n",
    "        users,movies = indices[0],indices[1]\n",
    "        x = self.drop1(torch.cat([self.u(users),self.m(movies)], dim=1))\n",
    "        x = self.drop2(F.relu(self.lin1(x)))\n",
    "        return torch.sigmoid(self.lin2(x)) * (5-0+1) + 0-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 10\n",
    "def train(model, opt, epochs=1):\n",
    "    best_acc = -1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for c, (x, y) in enumerate(loader):\n",
    "            model.train()\n",
    "\n",
    "            pred = model(x)\n",
    "\n",
    "#             criterion = nn.MSELoss()\n",
    "            loss = F.mse_loss(pred, y.float())\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            opt.step()\n",
    "            \n",
    "#             if e % print_every == 0:\n",
    "#                 print('Iteration %d, loss = %.4f' % (e, loss.item()))\n",
    "#                 acc = check_accuracy_part34(loader_val, model)\n",
    "#                 best_acc = acc if acc > best_acc else best_acc\n",
    "            \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "#             x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "#             y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            print(x, 'pred: ', scores, 'gt: ', y)\n",
    "#             _, preds = scores.max(1)\n",
    "#             num_correct += (preds == y.long()).sum()\n",
    "#             num_samples += preds.size(0)\n",
    "#         acc = float(num_correct) / num_samples\n",
    "#         print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "#         return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 1,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "epochs = 10\n",
    "N = 25\n",
    "\n",
    "df = make_colab_data(N,N)\n",
    "testdata = TestData(df)\n",
    "loader = data.DataLoader(testdata, **params)\n",
    "# print(df.loc[df['m_IJ'] > 0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-5\n",
    "# model = EmbeddingDotBias(N, N, 20)\n",
    "model = EmbeddingNet(N, N, n_factors=15)\n",
    "opt = optim.SGD(model.parameters(), 1e-4)\n",
    "train(model, opt, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy_part34(loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 2 1]\n",
      " [1 0 2]\n",
      " [1 1 1]\n",
      " [1 2 3]\n",
      " [2 0 4]\n",
      " [2 1 4]]\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['m_IJ'] > 0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
