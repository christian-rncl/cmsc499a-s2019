{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "bs = 64\n",
    "test_pct = .10\n",
    "val_pct = .20\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "from make_matrix import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, Sampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gidf = pd.read_csv('gi_dset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>effector</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AME1</td>\n",
       "      <td>BME0304</td>\n",
       "      <td>-2.416447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AME1</td>\n",
       "      <td>BME0390</td>\n",
       "      <td>-3.338498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AME1</td>\n",
       "      <td>BME0736</td>\n",
       "      <td>-2.054660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AME1</td>\n",
       "      <td>BME1013</td>\n",
       "      <td>-4.013577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AME1</td>\n",
       "      <td>BME1044</td>\n",
       "      <td>-2.855403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gene effector    zscore\n",
       "0  AME1  BME0304 -2.416447\n",
       "1  AME1  BME0390 -3.338498\n",
       "2  AME1  BME0736 -2.054660\n",
       "3  AME1  BME1013 -4.013577\n",
       "4  AME1  BME1044 -2.855403"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalize proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(df):\n",
    "    genes = df['gene'].unique()\n",
    "    effectors = df['effector'].unique()\n",
    "    gs_map = {v:i for i,v in enumerate(genes)}\n",
    "    es_map = {h:i for i,h in enumerate(effectors)}\n",
    "    \n",
    "    df.gene = df.gene.apply(lambda x : gs_map[x])\n",
    "    df.effector = df.effector.apply(lambda x : es_map[x])\n",
    "    df = df.sample(frac=1).reset_index()\n",
    "    return df[['gene', 'effector', 'zscore']], gs_map, es_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gidf, gs_map, es_map = numericalize(gidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>effector</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2210</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.602251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>20</td>\n",
       "      <td>0.508293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2629</td>\n",
       "      <td>10</td>\n",
       "      <td>0.226026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>6</td>\n",
       "      <td>1.254141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3904</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.539812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gene  effector    zscore\n",
       "0  2210        24 -0.602251\n",
       "1  2012        20  0.508293\n",
       "2  2629        10  0.226026\n",
       "3   221         6  1.254141\n",
       "4  3904        15 -0.539812"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_torch(arr, dtype):\n",
    "    t =  torch.from_numpy(np.array(arr)).type(dtype).to(device)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoaders(df):\n",
    "    X = list(zip(df.gene.values, df.effector.values))\n",
    "    y = df['zscore'].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_pct, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_pct, random_state=1)\n",
    "    \n",
    "    train_dset = TensorDataset(arr_to_torch(X_train, torch.long), arr_to_torch(y_train, torch.float32))\n",
    "    train_loader = DataLoader(train_dset, batch_size=bs, shuffle=True)\n",
    "    \n",
    "    val_dset = TensorDataset(arr_to_torch(X_val, torch.long), arr_to_torch(y_val, torch.float32))\n",
    "    val_loader = DataLoader(val_dset, batch_size=bs, shuffle=True)\n",
    "    \n",
    "    test_dset = TensorDataset(arr_to_torch(X_test, torch.long), arr_to_torch(y_test, torch.float32))\n",
    "    test_loader = DataLoader(test_dset, batch_size=bs, shuffle=True)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = getLoaders(gidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularize(array):\n",
    "    loss = torch.sum(array ** 2.0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, n_virus, n_human, k=18, c_vector=1.0, c_bias=1.0, writer=None):\n",
    "        super(MF, self).__init__()\n",
    "        self.writer = writer\n",
    "        self.k = k\n",
    "        self.n_virus = n_virus\n",
    "        self.n_human = n_human\n",
    "        self.c_bias = c_bias\n",
    "        self.c_vector = c_vector\n",
    "        \n",
    "        self.virus = nn.Embedding(n_virus, k)\n",
    "        self.human = nn.Embedding(n_human, k)\n",
    "        \n",
    "        # We've added new terms here:\n",
    "        self.bias_virus = nn.Embedding(n_virus, 1)\n",
    "        self.bias_human = nn.Embedding(n_human, 1)\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def forward(self, train_x):\n",
    "        virus_id = train_x[:, 0]\n",
    "        human_id = train_x[:, 1]\n",
    "        vector_virus = self.virus(virus_id)\n",
    "        vector_human = self.human(human_id)\n",
    "        \n",
    "        # Pull out biases\n",
    "        bias_virus = self.bias_virus(virus_id).squeeze()\n",
    "        bias_human = self.bias_human(human_id).squeeze()\n",
    "        biases = (self.bias + bias_virus + bias_human)\n",
    "        \n",
    "        ui_interaction = torch.sum(vector_virus * vector_human, dim=1)\n",
    "        \n",
    "        prediction = ui_interaction + biases\n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "#         loss_mse = F.binary_cross_entropy_with_logits(prediction, target.squeeze())\n",
    "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
    "    \n",
    "        # Add new regularization to the biases\n",
    "        prior_bias_virus =  l2_regularize(self.bias_virus.weight) * self.c_bias\n",
    "        prior_bias_human = l2_regularize(self.bias_human.weight) * self.c_bias\n",
    "        \n",
    "        prior_virus =  l2_regularize(self.virus.weight.data) * self.c_vector\n",
    "        prior_human = l2_regularize(self.human.weight.data) * self.c_vector\n",
    "        total = loss_mse + prior_virus + prior_human + prior_bias_virus + prior_bias_human\n",
    "        return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss, Accuracy, Precision, Recall\n",
    "from tensorboardX import SummaryWriter\n",
    "from ignite.metrics import MeanSquaredError, Loss\n",
    "from ignite.contrib.metrics import AveragePrecision, ROC_AUC\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, model, crit, optim, writer, train_loader, val_loader, test_loader, modelname):\n",
    "        self.model = model\n",
    "        self.crit = crit\n",
    "        self.optim = optim\n",
    "        self.writer = writer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.best_model = None\n",
    "        self.best_acc = 999\n",
    "        self.modelname = modelname\n",
    "        \n",
    "        self.trainer = create_supervised_trainer(model, optim, crit)\n",
    "        self.metrics = {'loss': Loss(crit), \"acc\": MeanSquaredError()}\n",
    "        self.evaluator = create_supervised_evaluator(model, metrics=self.metrics)\n",
    "        \n",
    "        ## Add events\n",
    "        self.trainer.add_event_handler(event_name=Events.ITERATION_COMPLETED, handler=self.log_training_loss)\n",
    "        self.trainer.add_event_handler(event_name=Events.EPOCH_COMPLETED, handler=self.log_validation_results)\n",
    "        self.trainer.add_event_handler(event_name=Events.COMPLETED, handler=self.log_test_results)\n",
    "        \n",
    "        print(model)\n",
    "        \n",
    "    def log_training_loss(self, engine, log_interval=400):\n",
    "        epoch = engine.state.epoch\n",
    "        itr = engine.state.iteration\n",
    "        fmt = \"TRAIN: Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
    "        msg = fmt.format(epoch, itr, len(self.train_loader), engine.state.output)\n",
    "        self.model.itr = itr\n",
    "        if itr % log_interval == 0:\n",
    "            print(msg)\n",
    "#             self.evaluator.run(self.train_loader)\n",
    "            \n",
    "#             metrics = self.evaluator.state.metrics\n",
    "#             mse = metrics['loss']\n",
    "#             ap = metrics['ap']\n",
    "#             roc = metrics['roc']\n",
    "            \n",
    "#             print(\"Epoch[{}] Validation MSE: {:.2f} Avg Prec: {:.2f} ROC: {:.2f} \"\n",
    "#                   .format(engine.state.epoch, mse, ap, roc))\n",
    "            \n",
    "#             self.writer.add_scalar(\"training/mse\", mse, engine.state.epoch)\n",
    "#             self.writer.add_scalar(\"training/ap\", ap, engine.state.epoch)\n",
    "#             self.writer.add_scalar(\"training/roc\", roc, engine.state.epoch)\n",
    "            \n",
    "    def log_validation_results(self, engine):\n",
    "        self.evaluator.run(self.val_loader)\n",
    "        \n",
    "        metrics = self.evaluator.state.metrics\n",
    "        mse = metrics['loss']\n",
    "        acc = metrics['acc']\n",
    "        \n",
    "        if acc < self.best_acc:\n",
    "            self.best_acc = acc\n",
    "            self.best_model = model.state_dict()\n",
    "        \n",
    "        print(\"VALIDATION Epoch[{}] Validation MSE: {:.2f} Acc: {:.2f}\"\n",
    "              .format(engine.state.epoch, mse, acc))\n",
    "        self.writer.add_scalar(\"validation/mse\", mse, engine.state.epoch)\n",
    "        self.writer.add_scalar(\"validation/acc\", acc, engine.state.epoch)\n",
    "        \n",
    "    def log_test_results(self, engine):\n",
    "        self.evaluator.run(self.test_loader)\n",
    "        \n",
    "        metrics = self.evaluator.state.metrics\n",
    "        mse = metrics['loss']\n",
    "        acc = metrics['acc']\n",
    "\n",
    "\n",
    "        print(\"TEST: Epoch[{}] Validation MSE: {:.2f} Acc: {:.2f}\"\n",
    "              .format(engine.state.epoch, mse, acc))\n",
    "        \n",
    "        print(\"BEST Acc: \", self.best_acc)\n",
    "        torch.save(self.best_model, './{}.pt'.format(self.modelname))\n",
    "        \n",
    "    def run(self, epochs):\n",
    "        self.trainer.run(self.train_loader, max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "k =20\n",
    "# regularizing bias\n",
    "c_bias = 1e-4\n",
    "c_vector = 1e-4\n",
    "batchsize = bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/FLU_simple_mf_02_bias_2019-05-19_23:34:59.604969\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'runs/FLU_simple_mf_02_bias_' + str(datetime.now()).replace(' ', '_')\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "model = MF(len(gs_map), len(es_map), writer=writer, k=k, c_bias=c_bias, c_vector=c_vector)\n",
    "crit = model.loss\n",
    "model.cuda()\n",
    "optim = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF(\n",
      "  (virus): Embedding(4450, 20)\n",
      "  (human): Embedding(36, 20)\n",
      "  (bias_virus): Embedding(4450, 1)\n",
      "  (bias_human): Embedding(36, 1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, crit, optim, writer, train_loader, val_loader, test_loader, 'flumodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: Epoch[1] Iteration[400/1897] Loss: 28.52\n",
      "TRAIN: Epoch[1] Iteration[800/1897] Loss: 23.36\n",
      "TRAIN: Epoch[1] Iteration[1200/1897] Loss: 20.53\n",
      "TRAIN: Epoch[1] Iteration[1600/1897] Loss: 21.19\n",
      "VALIDATION Epoch[1] Validation MSE: 19.49 Acc: 10.70\n",
      "TRAIN: Epoch[2] Iteration[2000/1897] Loss: 17.09\n",
      "TRAIN: Epoch[2] Iteration[2400/1897] Loss: 13.82\n",
      "TRAIN: Epoch[2] Iteration[2800/1897] Loss: 14.97\n",
      "TRAIN: Epoch[2] Iteration[3200/1897] Loss: 15.68\n",
      "TRAIN: Epoch[2] Iteration[3600/1897] Loss: 14.66\n",
      "VALIDATION Epoch[2] Validation MSE: 13.91 Acc: 5.49\n",
      "TEST: Epoch[2] Validation MSE: 13.87 Acc: 5.46\n",
      "BEST Acc:  5.493472703468645\n"
     ]
    }
   ],
   "source": [
    "trainer.run(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python deeplearning",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
