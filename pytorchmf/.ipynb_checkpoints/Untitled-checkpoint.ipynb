{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeG(n,m,p):\n",
    "    M = np.zeros((n, m))\n",
    "    G = nx.bipartite.random_graph(n,m,p)\n",
    "    observed = list(G.edges())\n",
    "    nodes = list(G.nodes())\n",
    "    for i in range(n):\n",
    "        for j in range(n, m + n):\n",
    "            if (i,j) in observed:\n",
    "                M[i][j - n] = 1\n",
    "            else:\n",
    "                M[i][j - n] = 0\n",
    "\n",
    "                    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n,p = 10,10,.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = makeG(m,n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "       [0., 1., 0., 1., 1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "       [0., 0., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMF(nn.Module):\n",
    "    def __init__(self, M, N, K):\n",
    "        super(NMF, self).__init__()\n",
    "        self.A = nn.Parameter(torch.rand(M, K, requires_grad=True))\n",
    "        self.S = nn.Parameter(torch.rand(K, N, requires_grad=True))\n",
    "        self.logistic = nn.Sigmoid()\n",
    "\n",
    "    def forward(self):\n",
    "        return self.logistic(torch.matmul(self.A, self.S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, crit, M, lr):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    pred = model()\n",
    "    loss = crit(pred, M)\n",
    "    loss.backward()\n",
    "#     print(optim.parameters())\n",
    "    for param in model.parameters():\n",
    "        param.data -= lr * param.grad\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(m,n,20)\n",
    "# optim = torch.optim.SGD(model.parameters(), lr=.08, momentum=.9)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=.01)\n",
    "crit = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3592, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.3533, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.3475, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.3417, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.3360, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.3304, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.3248, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.3193, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.3139, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.3085, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.3032, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.2979, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.2928, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.2876, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.2826, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    l = train(model, crit, torch.from_numpy(M).float(), .1)\n",
    "    if epoch % 10 == 0:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 1., 1., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "        [0., 1., 0., 1., 1., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "        [0., 0., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], grad_fn=<RoundBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.round(model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "       [0., 1., 0., 1., 1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "       [0., 0., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916666666666666"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(M, model().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python deeplearning",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
