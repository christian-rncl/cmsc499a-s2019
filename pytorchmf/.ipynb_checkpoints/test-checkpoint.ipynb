{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "from make_matrix import *\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.txt', delim_whitespace=True, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STAT1</td>\n",
       "      <td>ATF3</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STAT1</td>\n",
       "      <td>NFYB</td>\n",
       "      <td>71</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STAT1</td>\n",
       "      <td>SP1</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZFP238</td>\n",
       "      <td>EGR1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZFP238</td>\n",
       "      <td>IRF9</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1   2   3\n",
       "0   STAT1  ATF3  71   3\n",
       "1   STAT1  NFYB  71  85\n",
       "2   STAT1   SP1  71  70\n",
       "3  ZFP238  EGR1  15   8\n",
       "4  ZFP238  IRF9  15  83"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = df[2].unique()\n",
    "hs = df[3].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = []\n",
    "for _, row in df.iterrows():\n",
    "    observed.append((row[2], row[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_df = {'vs':[], 'hs':[], 'edge':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in vs:\n",
    "    for h in hs:\n",
    "        net_df['vs'].append(v)\n",
    "        net_df['hs'].append(h)\n",
    "        if (v,h) in observed:\n",
    "            net_df['edge'].append(1.0)\n",
    "        else:\n",
    "            net_df['edge'].append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "netdf = pd.DataFrame(net_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(netdf.loc[netdf['edge'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "netdf = netdf.sample(frac=1).reset_index()[['vs', 'hs', 'edge']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure indices are continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vs</th>\n",
       "      <th>hs</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>49</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vs  hs  edge\n",
       "0  91  42   1.0\n",
       "1  90  49   0.0\n",
       "2   0  21   0.0\n",
       "3  58  10   1.0\n",
       "4   1  10   0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.sort()\n",
    "hs.sort()\n",
    "vs_map = {v:i for i,v in enumerate(vs)}\n",
    "hs_map = {h:i for i, h in enumerate(hs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vs</th>\n",
       "      <th>hs</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vs  hs  edge\n",
       "0  37  20   1.0\n",
       "1  36  23   0.0\n",
       "2   0  12   0.0\n",
       "3  26   6   1.0\n",
       "4   1   6   0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netdf.vs = netdf.vs.apply(lambda x : vs_map[x])\n",
    "netdf.hs = netdf.hs.apply(lambda x : hs_map[x])\n",
    "netdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(zip(netdf.vs.values, netdf.hs.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = netdf['edge'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_torch(arr, dtype):\n",
    "    t =  torch.from_numpy(np.array(arr)).type(dtype).to(device)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = TensorDataset(arr_to_torch(X_train, torch.long), arr_to_torch(y_train, torch.float32))\n",
    "train_loader = DataLoader(train_dset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dset = TensorDataset(arr_to_torch(X_val, torch.long), arr_to_torch(y_val, torch.float32))\n",
    "val_loader = DataLoader(val_dset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset = TensorDataset(arr_to_torch(X_test, torch.long), arr_to_torch(y_test, torch.float32))\n",
    "test_loader = DataLoader(test_dset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularize(array):\n",
    "    loss = torch.sum(array ** 2.0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, n_virus, n_human, k=18, c_vector=1.0, c_bias=1.0, writer=None):\n",
    "        super(MF, self).__init__()\n",
    "        self.writer = writer\n",
    "        self.k = k\n",
    "        self.n_virus = n_virus\n",
    "        self.n_human = n_human\n",
    "        self.c_bias = c_bias\n",
    "        self.c_vector = c_vector\n",
    "        \n",
    "        self.virus = nn.Embedding(n_virus, k)\n",
    "        self.human = nn.Embedding(n_human, k)\n",
    "        \n",
    "        # We've added new terms here:\n",
    "        self.bias_virus = nn.Embedding(n_virus, 1)\n",
    "        self.bias_human = nn.Embedding(n_human, 1)\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "        \n",
    "#         self.affine = nn.Linear(in_features=self.k, out_features=1)\n",
    "#         self.logistic = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, train_x):\n",
    "        virus_id = train_x[:, 0]\n",
    "        human_id = train_x[:, 1]\n",
    "        vector_virus = self.virus(virus_id)\n",
    "        vector_human = self.human(human_id)\n",
    "        \n",
    "        # Pull out biases\n",
    "        bias_virus = self.bias_virus(virus_id).squeeze()\n",
    "        bias_human = self.bias_human(human_id).squeeze()\n",
    "        biases = (self.bias + bias_virus + bias_human)\n",
    "        \n",
    "        ui_interaction = torch.sum(vector_virus * vector_human, dim=1)\n",
    "        \n",
    "        prediction = ui_interaction + biases\n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "#         loss_mse = F.binary_cross_entropy_with_logits(prediction, target.squeeze())\n",
    "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
    "    \n",
    "        # Add new regularization to the biases\n",
    "        prior_bias_virus =  l2_regularize(self.bias_virus.weight) * self.c_bias\n",
    "        prior_bias_human = l2_regularize(self.bias_human.weight) * self.c_bias\n",
    "        \n",
    "        prior_virus =  l2_regularize(self.virus.weight.data) * self.c_vector\n",
    "        prior_human = l2_regularize(self.human.weight.data) * self.c_vector\n",
    "        total = loss_mse + prior_virus + prior_human + prior_bias_virus + prior_bias_human\n",
    "        return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss, Accuracy, Precision, Recall\n",
    "from tensorboardX import SummaryWriter\n",
    "from ignite.metrics import MeanSquaredError, Loss\n",
    "from ignite.contrib.metrics import AveragePrecision, ROC_AUC\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/simple_mf_02_bias_2019-05-16_21:14:29.778122\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "lr = 1e-3\n",
    "k =20\n",
    "# New parameter for regularizing bias\n",
    "c_bias = 1e-4\n",
    "c_vector = 1e-4\n",
    "batchsize = bs\n",
    "log_dir = 'runs/simple_mf_02_bias_' + str(datetime.now()).replace(' ', '_')\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MF(\n",
       "  (virus): Embedding(40, 20)\n",
       "  (human): Embedding(40, 20)\n",
       "  (bias_virus): Embedding(40, 1)\n",
       "  (bias_human): Embedding(40, 1)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "# crit = model.loss\n",
    "crit = nn.MSELoss()\n",
    "\n",
    "model = MF(len(vs_map), len(hs_map), writer=writer, k=k, c_bias=c_bias, c_vector=c_vector)\n",
    "# model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "trainer = create_supervised_trainer(model, optimizer, model.loss)\n",
    "metrics = {'loss': Loss(crit), 'ap': AveragePrecision(), \"acc\": Accuracy(), \"roc\": ROC_AUC()}\n",
    "evaluator = create_supervised_evaluator(model, metrics=metrics)\n",
    "\n",
    "def log_training_loss(engine, log_interval=400):\n",
    "    epoch = engine.state.epoch\n",
    "    itr = engine.state.iteration\n",
    "    fmt = \"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
    "    msg = fmt.format(epoch, itr, len(train_loader), engine.state.output)\n",
    "    model.itr = itr\n",
    "    if itr % log_interval == 0:\n",
    "        print(msg)\n",
    "        metrics = evaluator.state.metrics\n",
    "        mse = metrics['loss']\n",
    "        avg_precision = metrics['ap']\n",
    "        accuracy = metrics['acc']\n",
    "        roc = metrics['roc']\n",
    "        writer.add_scalar(\"training/mse\", mse, engine.state.epoch)\n",
    "        writer.add_scalar(\"training/ap\", avg_precision, engine.state.epoch)\n",
    "        writer.add_scalar(\"training/accuracy\", accuracy, engine.state.epoch)\n",
    "        writer.add_scalar(\"training/roc\", roc, engine.state.epoch)\n",
    "\n",
    "trainer.add_event_handler(event_name=Events.ITERATION_COMPLETED, handler=log_training_loss)\n",
    "\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    mse = metrics['loss']\n",
    "    avg_precision = metrics['ap']\n",
    "    accuracy = metrics['acc']\n",
    "    roc = metrics['roc']\n",
    "    print(\"Epoch[{}] Validation MSE: {:.2f} Avg Prec: {:.2f} acc: {:.2f} ROC: {:.2f} \"\n",
    "          .format(engine.state.epoch, mse, avg_precision, accuracy, roc))\n",
    "    writer.add_scalar(\"validation/mse\", mse, engine.state.epoch)\n",
    "    writer.add_scalar(\"validation/avg_precision\", avg_precision, engine.state.epoch)\n",
    "    writer.add_scalar(\"validation/accuracy\", accuracy, engine.state.epoch)\n",
    "    writer.add_scalar(\"validation/roc\", roc, engine.state.epoch)\n",
    "\n",
    "    \n",
    "def log_test_results(engine):\n",
    "    evaluator.run(test_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    mse = metrics['loss']\n",
    "    avg_precision = metrics['ap']\n",
    "    accuracy = metrics['acc']\n",
    "    roc = metrics['roc']\n",
    "\n",
    "    print(\"TEST: Epoch[{}] Validation MSE: {:.2f} Avg Prec: {:.2f} acc: {:.2f} ROC: {:.2f}\"\n",
    "          .format(engine.state.epoch, mse, avg_precision, accuracy, roc))\n",
    "\n",
    "\n",
    "trainer.add_event_handler(event_name=Events.EPOCH_COMPLETED, handler=log_validation_results)\n",
    "trainer.add_event_handler(event_name=Events.COMPLETED, handler=log_test_results)\n",
    "\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MF(\n",
       "  (virus): Embedding(40, 20)\n",
       "  (human): Embedding(40, 20)\n",
       "  (bias_virus): Embedding(40, 1)\n",
       "  (bias_human): Embedding(40, 1)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Validation MSE: 20.83 Avg Prec: 0.42 acc: 0.08 ROC: 0.54 \n",
      "Epoch[2] Validation MSE: 20.26 Avg Prec: 0.42 acc: 0.08 ROC: 0.54 \n",
      "Epoch[3] Validation MSE: 19.71 Avg Prec: 0.42 acc: 0.06 ROC: 0.54 \n",
      "Epoch[4] Validation MSE: 19.19 Avg Prec: 0.43 acc: 0.08 ROC: 0.54 \n",
      "Epoch[5] Validation MSE: 18.69 Avg Prec: 0.43 acc: 0.08 ROC: 0.54 \n",
      "Epoch[6] Validation MSE: 18.22 Avg Prec: 0.43 acc: 0.09 ROC: 0.54 \n",
      "Epoch[7] Validation MSE: 17.76 Avg Prec: 0.43 acc: 0.09 ROC: 0.54 \n",
      "Epoch[8] Validation MSE: 17.33 Avg Prec: 0.44 acc: 0.09 ROC: 0.54 \n",
      "Epoch[9] Validation MSE: 16.91 Avg Prec: 0.44 acc: 0.10 ROC: 0.54 \n",
      "Epoch[10] Iteration[400/41] Loss: 14.03\n",
      "Epoch[10] Validation MSE: 16.51 Avg Prec: 0.45 acc: 0.10 ROC: 0.54 \n",
      "Epoch[11] Validation MSE: 16.13 Avg Prec: 0.45 acc: 0.11 ROC: 0.54 \n",
      "Epoch[12] Validation MSE: 15.76 Avg Prec: 0.45 acc: 0.13 ROC: 0.54 \n",
      "Epoch[13] Validation MSE: 15.40 Avg Prec: 0.45 acc: 0.13 ROC: 0.54 \n",
      "Epoch[14] Validation MSE: 15.06 Avg Prec: 0.45 acc: 0.13 ROC: 0.55 \n",
      "Epoch[15] Validation MSE: 14.73 Avg Prec: 0.45 acc: 0.12 ROC: 0.55 \n",
      "Epoch[16] Validation MSE: 14.41 Avg Prec: 0.45 acc: 0.13 ROC: 0.55 \n",
      "Epoch[17] Validation MSE: 14.11 Avg Prec: 0.45 acc: 0.14 ROC: 0.55 \n",
      "Epoch[18] Validation MSE: 13.81 Avg Prec: 0.45 acc: 0.15 ROC: 0.55 \n",
      "Epoch[19] Validation MSE: 13.53 Avg Prec: 0.45 acc: 0.14 ROC: 0.55 \n",
      "Epoch[20] Iteration[800/41] Loss: 6.66\n",
      "Epoch[20] Validation MSE: 13.25 Avg Prec: 0.45 acc: 0.15 ROC: 0.55 \n",
      "Epoch[21] Validation MSE: 12.99 Avg Prec: 0.46 acc: 0.15 ROC: 0.55 \n",
      "Epoch[22] Validation MSE: 12.73 Avg Prec: 0.46 acc: 0.15 ROC: 0.55 \n",
      "Epoch[23] Validation MSE: 12.48 Avg Prec: 0.46 acc: 0.15 ROC: 0.55 \n",
      "Epoch[24] Validation MSE: 12.24 Avg Prec: 0.46 acc: 0.15 ROC: 0.55 \n",
      "Epoch[25] Validation MSE: 12.00 Avg Prec: 0.46 acc: 0.15 ROC: 0.55 \n",
      "Epoch[26] Validation MSE: 11.78 Avg Prec: 0.46 acc: 0.15 ROC: 0.55 \n",
      "Epoch[27] Validation MSE: 11.56 Avg Prec: 0.46 acc: 0.15 ROC: 0.55 \n",
      "Epoch[28] Validation MSE: 11.34 Avg Prec: 0.46 acc: 0.15 ROC: 0.55 \n",
      "Epoch[29] Validation MSE: 11.14 Avg Prec: 0.46 acc: 0.15 ROC: 0.55 \n",
      "Epoch[30] Iteration[1200/41] Loss: 9.29\n",
      "Epoch[30] Validation MSE: 10.93 Avg Prec: 0.46 acc: 0.15 ROC: 0.56 \n",
      "Epoch[31] Validation MSE: 10.74 Avg Prec: 0.46 acc: 0.15 ROC: 0.56 \n",
      "Epoch[32] Validation MSE: 10.55 Avg Prec: 0.46 acc: 0.15 ROC: 0.56 \n",
      "Epoch[33] Validation MSE: 10.36 Avg Prec: 0.46 acc: 0.15 ROC: 0.56 \n",
      "Epoch[34] Validation MSE: 10.18 Avg Prec: 0.46 acc: 0.16 ROC: 0.56 \n",
      "Epoch[35] Validation MSE: 10.00 Avg Prec: 0.46 acc: 0.16 ROC: 0.56 \n",
      "Epoch[36] Validation MSE: 9.83 Avg Prec: 0.46 acc: 0.17 ROC: 0.56 \n",
      "Epoch[37] Validation MSE: 9.66 Avg Prec: 0.46 acc: 0.17 ROC: 0.56 \n",
      "Epoch[38] Validation MSE: 9.50 Avg Prec: 0.47 acc: 0.17 ROC: 0.56 \n",
      "Epoch[39] Validation MSE: 9.34 Avg Prec: 0.47 acc: 0.17 ROC: 0.56 \n",
      "Epoch[40] Iteration[1600/41] Loss: 6.59\n",
      "Epoch[40] Validation MSE: 9.19 Avg Prec: 0.47 acc: 0.17 ROC: 0.56 \n",
      "Epoch[41] Validation MSE: 9.03 Avg Prec: 0.47 acc: 0.17 ROC: 0.56 \n",
      "Epoch[42] Validation MSE: 8.89 Avg Prec: 0.47 acc: 0.17 ROC: 0.56 \n",
      "Epoch[43] Validation MSE: 8.74 Avg Prec: 0.47 acc: 0.16 ROC: 0.56 \n",
      "Epoch[44] Validation MSE: 8.60 Avg Prec: 0.47 acc: 0.15 ROC: 0.56 \n",
      "Epoch[45] Validation MSE: 8.46 Avg Prec: 0.47 acc: 0.15 ROC: 0.56 \n",
      "Epoch[46] Validation MSE: 8.32 Avg Prec: 0.47 acc: 0.15 ROC: 0.56 \n",
      "Epoch[47] Validation MSE: 8.19 Avg Prec: 0.47 acc: 0.15 ROC: 0.56 \n",
      "Epoch[48] Validation MSE: 8.06 Avg Prec: 0.47 acc: 0.15 ROC: 0.56 \n",
      "Epoch[49] Iteration[2000/41] Loss: 3.15\n",
      "Epoch[49] Validation MSE: 7.93 Avg Prec: 0.47 acc: 0.15 ROC: 0.56 \n",
      "Epoch[50] Validation MSE: 7.81 Avg Prec: 0.47 acc: 0.17 ROC: 0.56 \n",
      "Epoch[51] Validation MSE: 7.68 Avg Prec: 0.47 acc: 0.18 ROC: 0.56 \n",
      "Epoch[52] Validation MSE: 7.56 Avg Prec: 0.47 acc: 0.18 ROC: 0.56 \n",
      "Epoch[53] Validation MSE: 7.45 Avg Prec: 0.47 acc: 0.18 ROC: 0.56 \n",
      "Epoch[54] Validation MSE: 7.33 Avg Prec: 0.47 acc: 0.17 ROC: 0.56 \n",
      "Epoch[55] Validation MSE: 7.22 Avg Prec: 0.47 acc: 0.17 ROC: 0.56 \n",
      "Epoch[56] Validation MSE: 7.11 Avg Prec: 0.47 acc: 0.17 ROC: 0.56 \n",
      "Epoch[57] Validation MSE: 7.00 Avg Prec: 0.47 acc: 0.17 ROC: 0.56 \n",
      "Epoch[58] Validation MSE: 6.89 Avg Prec: 0.48 acc: 0.17 ROC: 0.56 \n",
      "Epoch[59] Iteration[2400/41] Loss: 4.49\n",
      "Epoch[59] Validation MSE: 6.78 Avg Prec: 0.48 acc: 0.17 ROC: 0.56 \n",
      "Epoch[60] Validation MSE: 6.68 Avg Prec: 0.48 acc: 0.17 ROC: 0.56 \n",
      "Epoch[61] Validation MSE: 6.58 Avg Prec: 0.48 acc: 0.17 ROC: 0.56 \n",
      "Epoch[62] Validation MSE: 6.48 Avg Prec: 0.48 acc: 0.17 ROC: 0.56 \n",
      "Epoch[63] Validation MSE: 6.38 Avg Prec: 0.48 acc: 0.17 ROC: 0.56 \n",
      "Epoch[64] Validation MSE: 6.28 Avg Prec: 0.48 acc: 0.18 ROC: 0.57 \n",
      "Epoch[65] Validation MSE: 6.19 Avg Prec: 0.48 acc: 0.18 ROC: 0.57 \n",
      "Epoch[66] Validation MSE: 6.10 Avg Prec: 0.48 acc: 0.18 ROC: 0.57 \n",
      "Epoch[67] Validation MSE: 6.00 Avg Prec: 0.48 acc: 0.18 ROC: 0.57 \n",
      "Epoch[68] Validation MSE: 5.91 Avg Prec: 0.48 acc: 0.18 ROC: 0.57 \n",
      "Epoch[69] Iteration[2800/41] Loss: 1.82\n",
      "Epoch[69] Validation MSE: 5.83 Avg Prec: 0.48 acc: 0.19 ROC: 0.57 \n",
      "Epoch[70] Validation MSE: 5.74 Avg Prec: 0.48 acc: 0.19 ROC: 0.57 \n",
      "Epoch[71] Validation MSE: 5.65 Avg Prec: 0.48 acc: 0.19 ROC: 0.57 \n",
      "Epoch[72] Validation MSE: 5.57 Avg Prec: 0.49 acc: 0.19 ROC: 0.57 \n",
      "Epoch[73] Validation MSE: 5.48 Avg Prec: 0.49 acc: 0.20 ROC: 0.57 \n",
      "Epoch[74] Validation MSE: 5.40 Avg Prec: 0.49 acc: 0.20 ROC: 0.57 \n",
      "Epoch[75] Validation MSE: 5.32 Avg Prec: 0.49 acc: 0.20 ROC: 0.57 \n",
      "Epoch[76] Validation MSE: 5.24 Avg Prec: 0.49 acc: 0.22 ROC: 0.57 \n",
      "Epoch[77] Validation MSE: 5.16 Avg Prec: 0.49 acc: 0.22 ROC: 0.57 \n",
      "Epoch[78] Validation MSE: 5.08 Avg Prec: 0.49 acc: 0.22 ROC: 0.57 \n",
      "Epoch[79] Iteration[3200/41] Loss: 2.28\n",
      "Epoch[79] Validation MSE: 5.01 Avg Prec: 0.49 acc: 0.22 ROC: 0.57 \n",
      "Epoch[80] Validation MSE: 4.93 Avg Prec: 0.49 acc: 0.22 ROC: 0.57 \n",
      "Epoch[81] Validation MSE: 4.86 Avg Prec: 0.49 acc: 0.22 ROC: 0.57 \n",
      "Epoch[82] Validation MSE: 4.79 Avg Prec: 0.49 acc: 0.22 ROC: 0.57 \n",
      "Epoch[83] Validation MSE: 4.71 Avg Prec: 0.49 acc: 0.22 ROC: 0.57 \n",
      "Epoch[84] Validation MSE: 4.64 Avg Prec: 0.49 acc: 0.22 ROC: 0.57 \n",
      "Epoch[85] Validation MSE: 4.57 Avg Prec: 0.49 acc: 0.22 ROC: 0.57 \n",
      "Epoch[86] Validation MSE: 4.50 Avg Prec: 0.49 acc: 0.22 ROC: 0.57 \n",
      "Epoch[87] Validation MSE: 4.44 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[88] Iteration[3600/41] Loss: 0.84\n",
      "Epoch[88] Validation MSE: 4.37 Avg Prec: 0.50 acc: 0.23 ROC: 0.57 \n",
      "Epoch[89] Validation MSE: 4.30 Avg Prec: 0.50 acc: 0.23 ROC: 0.57 \n",
      "Epoch[90] Validation MSE: 4.24 Avg Prec: 0.50 acc: 0.23 ROC: 0.57 \n",
      "Epoch[91] Validation MSE: 4.18 Avg Prec: 0.50 acc: 0.23 ROC: 0.57 \n",
      "Epoch[92] Validation MSE: 4.11 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[93] Validation MSE: 4.05 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[94] Validation MSE: 3.99 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[95] Validation MSE: 3.93 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[96] Validation MSE: 3.87 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[97] Validation MSE: 3.81 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[98] Iteration[4000/41] Loss: 1.32\n",
      "Epoch[98] Validation MSE: 3.75 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[99] Validation MSE: 3.70 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[100] Validation MSE: 3.64 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[101] Validation MSE: 3.58 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[102] Validation MSE: 3.53 Avg Prec: 0.50 acc: 0.24 ROC: 0.57 \n",
      "Epoch[103] Validation MSE: 3.48 Avg Prec: 0.50 acc: 0.24 ROC: 0.58 \n",
      "Epoch[104] Validation MSE: 3.42 Avg Prec: 0.50 acc: 0.25 ROC: 0.58 \n",
      "Epoch[105] Validation MSE: 3.37 Avg Prec: 0.50 acc: 0.26 ROC: 0.58 \n",
      "Epoch[106] Validation MSE: 3.32 Avg Prec: 0.50 acc: 0.26 ROC: 0.58 \n",
      "Epoch[107] Validation MSE: 3.27 Avg Prec: 0.50 acc: 0.27 ROC: 0.58 \n",
      "Epoch[108] Iteration[4400/41] Loss: 0.66\n",
      "Epoch[108] Validation MSE: 3.22 Avg Prec: 0.50 acc: 0.26 ROC: 0.58 \n",
      "Epoch[109] Validation MSE: 3.17 Avg Prec: 0.50 acc: 0.27 ROC: 0.58 \n",
      "Epoch[110] Validation MSE: 3.12 Avg Prec: 0.50 acc: 0.28 ROC: 0.58 \n",
      "Epoch[111] Validation MSE: 3.07 Avg Prec: 0.50 acc: 0.28 ROC: 0.58 \n",
      "Epoch[112] Validation MSE: 3.03 Avg Prec: 0.50 acc: 0.28 ROC: 0.58 \n",
      "Epoch[113] Validation MSE: 2.98 Avg Prec: 0.50 acc: 0.29 ROC: 0.58 \n",
      "Epoch[114] Validation MSE: 2.94 Avg Prec: 0.50 acc: 0.28 ROC: 0.58 \n",
      "Epoch[115] Validation MSE: 2.89 Avg Prec: 0.50 acc: 0.28 ROC: 0.58 \n",
      "Epoch[116] Validation MSE: 2.85 Avg Prec: 0.50 acc: 0.28 ROC: 0.58 \n",
      "Epoch[117] Validation MSE: 2.80 Avg Prec: 0.50 acc: 0.27 ROC: 0.58 \n",
      "Epoch[118] Iteration[4800/41] Loss: 0.41\n",
      "Epoch[118] Validation MSE: 2.76 Avg Prec: 0.50 acc: 0.26 ROC: 0.58 \n",
      "Epoch[119] Validation MSE: 2.72 Avg Prec: 0.50 acc: 0.26 ROC: 0.58 \n",
      "Epoch[120] Validation MSE: 2.68 Avg Prec: 0.50 acc: 0.26 ROC: 0.58 \n",
      "Epoch[121] Validation MSE: 2.64 Avg Prec: 0.50 acc: 0.26 ROC: 0.58 \n",
      "Epoch[122] Validation MSE: 2.60 Avg Prec: 0.50 acc: 0.29 ROC: 0.58 \n",
      "Epoch[123] Validation MSE: 2.56 Avg Prec: 0.50 acc: 0.31 ROC: 0.58 \n",
      "Epoch[124] Validation MSE: 2.52 Avg Prec: 0.50 acc: 0.31 ROC: 0.58 \n",
      "Epoch[125] Validation MSE: 2.48 Avg Prec: 0.50 acc: 0.31 ROC: 0.58 \n",
      "Epoch[126] Validation MSE: 2.44 Avg Prec: 0.50 acc: 0.31 ROC: 0.58 \n",
      "Epoch[127] Iteration[5200/41] Loss: 0.46\n",
      "Epoch[127] Validation MSE: 2.41 Avg Prec: 0.50 acc: 0.31 ROC: 0.58 \n",
      "Epoch[128] Validation MSE: 2.37 Avg Prec: 0.50 acc: 0.31 ROC: 0.58 \n",
      "Epoch[129] Validation MSE: 2.33 Avg Prec: 0.50 acc: 0.31 ROC: 0.58 \n",
      "Epoch[130] Validation MSE: 2.30 Avg Prec: 0.50 acc: 0.31 ROC: 0.58 \n",
      "Epoch[131] Validation MSE: 2.26 Avg Prec: 0.50 acc: 0.32 ROC: 0.58 \n",
      "Epoch[132] Validation MSE: 2.23 Avg Prec: 0.51 acc: 0.33 ROC: 0.58 \n",
      "Epoch[133] Validation MSE: 2.20 Avg Prec: 0.51 acc: 0.33 ROC: 0.58 \n",
      "Epoch[134] Validation MSE: 2.16 Avg Prec: 0.51 acc: 0.33 ROC: 0.58 \n",
      "Epoch[135] Validation MSE: 2.13 Avg Prec: 0.51 acc: 0.33 ROC: 0.59 \n",
      "Epoch[136] Validation MSE: 2.10 Avg Prec: 0.51 acc: 0.33 ROC: 0.59 \n",
      "Epoch[137] Iteration[5600/41] Loss: 0.22\n",
      "Epoch[137] Validation MSE: 2.07 Avg Prec: 0.51 acc: 0.33 ROC: 0.59 \n",
      "Epoch[138] Validation MSE: 2.04 Avg Prec: 0.51 acc: 0.33 ROC: 0.59 \n",
      "Epoch[139] Validation MSE: 2.01 Avg Prec: 0.51 acc: 0.33 ROC: 0.59 \n",
      "Epoch[140] Validation MSE: 1.98 Avg Prec: 0.51 acc: 0.35 ROC: 0.59 \n",
      "Epoch[141] Validation MSE: 1.95 Avg Prec: 0.51 acc: 0.35 ROC: 0.59 \n",
      "Epoch[142] Validation MSE: 1.92 Avg Prec: 0.51 acc: 0.35 ROC: 0.59 \n",
      "Epoch[143] Validation MSE: 1.89 Avg Prec: 0.51 acc: 0.36 ROC: 0.59 \n",
      "Epoch[144] Validation MSE: 1.86 Avg Prec: 0.52 acc: 0.36 ROC: 0.59 \n",
      "Epoch[145] Validation MSE: 1.84 Avg Prec: 0.52 acc: 0.36 ROC: 0.59 \n",
      "Epoch[146] Validation MSE: 1.81 Avg Prec: 0.52 acc: 0.37 ROC: 0.59 \n",
      "Epoch[147] Iteration[6000/41] Loss: 0.36\n",
      "Epoch[147] Validation MSE: 1.78 Avg Prec: 0.52 acc: 0.35 ROC: 0.60 \n",
      "Epoch[148] Validation MSE: 1.76 Avg Prec: 0.52 acc: 0.35 ROC: 0.60 \n",
      "Epoch[149] Validation MSE: 1.73 Avg Prec: 0.52 acc: 0.35 ROC: 0.60 \n",
      "Epoch[150] Validation MSE: 1.71 Avg Prec: 0.52 acc: 0.35 ROC: 0.60 \n",
      "Epoch[151] Validation MSE: 1.69 Avg Prec: 0.52 acc: 0.35 ROC: 0.60 \n",
      "Epoch[152] Validation MSE: 1.66 Avg Prec: 0.52 acc: 0.36 ROC: 0.60 \n",
      "Epoch[153] Validation MSE: 1.64 Avg Prec: 0.52 acc: 0.36 ROC: 0.60 \n",
      "Epoch[154] Validation MSE: 1.62 Avg Prec: 0.52 acc: 0.37 ROC: 0.60 \n",
      "Epoch[155] Validation MSE: 1.59 Avg Prec: 0.52 acc: 0.37 ROC: 0.60 \n",
      "Epoch[156] Validation MSE: 1.57 Avg Prec: 0.52 acc: 0.37 ROC: 0.60 \n",
      "Epoch[157] Iteration[6400/41] Loss: 0.28\n",
      "Epoch[157] Validation MSE: 1.55 Avg Prec: 0.52 acc: 0.36 ROC: 0.60 \n",
      "Epoch[158] Validation MSE: 1.53 Avg Prec: 0.52 acc: 0.36 ROC: 0.60 \n",
      "Epoch[159] Validation MSE: 1.51 Avg Prec: 0.52 acc: 0.36 ROC: 0.60 \n",
      "Epoch[160] Validation MSE: 1.49 Avg Prec: 0.52 acc: 0.36 ROC: 0.60 \n",
      "Epoch[161] Validation MSE: 1.47 Avg Prec: 0.52 acc: 0.36 ROC: 0.60 \n",
      "Epoch[162] Validation MSE: 1.45 Avg Prec: 0.53 acc: 0.36 ROC: 0.60 \n",
      "Epoch[163] Validation MSE: 1.43 Avg Prec: 0.53 acc: 0.37 ROC: 0.61 \n",
      "Epoch[164] Validation MSE: 1.41 Avg Prec: 0.53 acc: 0.38 ROC: 0.61 \n",
      "Epoch[165] Validation MSE: 1.39 Avg Prec: 0.53 acc: 0.38 ROC: 0.61 \n",
      "Epoch[166] Iteration[6800/41] Loss: 0.14\n",
      "Epoch[166] Validation MSE: 1.37 Avg Prec: 0.53 acc: 0.38 ROC: 0.61 \n",
      "Epoch[167] Validation MSE: 1.36 Avg Prec: 0.53 acc: 0.38 ROC: 0.61 \n",
      "Epoch[168] Validation MSE: 1.34 Avg Prec: 0.53 acc: 0.38 ROC: 0.61 \n",
      "Epoch[169] Validation MSE: 1.32 Avg Prec: 0.53 acc: 0.38 ROC: 0.61 \n",
      "Epoch[170] Validation MSE: 1.31 Avg Prec: 0.53 acc: 0.38 ROC: 0.61 \n",
      "Epoch[171] Validation MSE: 1.29 Avg Prec: 0.53 acc: 0.40 ROC: 0.61 \n",
      "Epoch[172] Validation MSE: 1.27 Avg Prec: 0.53 acc: 0.41 ROC: 0.61 \n",
      "Epoch[173] Validation MSE: 1.26 Avg Prec: 0.53 acc: 0.42 ROC: 0.61 \n",
      "Epoch[174] Validation MSE: 1.24 Avg Prec: 0.53 acc: 0.42 ROC: 0.61 \n",
      "Epoch[175] Validation MSE: 1.23 Avg Prec: 0.53 acc: 0.42 ROC: 0.61 \n",
      "Epoch[176] Iteration[7200/41] Loss: 0.20\n",
      "Epoch[176] Validation MSE: 1.21 Avg Prec: 0.54 acc: 0.42 ROC: 0.62 \n",
      "Epoch[177] Validation MSE: 1.20 Avg Prec: 0.54 acc: 0.42 ROC: 0.62 \n",
      "Epoch[178] Validation MSE: 1.18 Avg Prec: 0.54 acc: 0.42 ROC: 0.62 \n",
      "Epoch[179] Validation MSE: 1.17 Avg Prec: 0.54 acc: 0.42 ROC: 0.62 \n",
      "Epoch[180] Validation MSE: 1.16 Avg Prec: 0.54 acc: 0.42 ROC: 0.62 \n",
      "Epoch[181] Validation MSE: 1.15 Avg Prec: 0.54 acc: 0.42 ROC: 0.62 \n",
      "Epoch[182] Validation MSE: 1.13 Avg Prec: 0.54 acc: 0.42 ROC: 0.62 \n",
      "Epoch[183] Validation MSE: 1.12 Avg Prec: 0.54 acc: 0.42 ROC: 0.62 \n",
      "Epoch[184] Validation MSE: 1.11 Avg Prec: 0.54 acc: 0.43 ROC: 0.62 \n",
      "Epoch[185] Validation MSE: 1.10 Avg Prec: 0.54 acc: 0.44 ROC: 0.62 \n",
      "Epoch[186] Iteration[7600/41] Loss: 0.19\n",
      "Epoch[186] Validation MSE: 1.08 Avg Prec: 0.54 acc: 0.44 ROC: 0.62 \n",
      "Epoch[187] Validation MSE: 1.07 Avg Prec: 0.54 acc: 0.44 ROC: 0.62 \n",
      "Epoch[188] Validation MSE: 1.06 Avg Prec: 0.54 acc: 0.44 ROC: 0.62 \n",
      "Epoch[189] Validation MSE: 1.05 Avg Prec: 0.54 acc: 0.44 ROC: 0.62 \n",
      "Epoch[190] Validation MSE: 1.04 Avg Prec: 0.54 acc: 0.44 ROC: 0.62 \n",
      "Epoch[191] Validation MSE: 1.03 Avg Prec: 0.54 acc: 0.44 ROC: 0.62 \n",
      "Epoch[192] Validation MSE: 1.02 Avg Prec: 0.54 acc: 0.44 ROC: 0.63 \n",
      "Epoch[193] Validation MSE: 1.01 Avg Prec: 0.54 acc: 0.45 ROC: 0.63 \n",
      "Epoch[194] Validation MSE: 1.00 Avg Prec: 0.54 acc: 0.46 ROC: 0.63 \n",
      "Epoch[195] Validation MSE: 0.99 Avg Prec: 0.55 acc: 0.46 ROC: 0.63 \n",
      "Epoch[196] Iteration[8000/41] Loss: 0.16\n",
      "Epoch[196] Validation MSE: 0.98 Avg Prec: 0.54 acc: 0.46 ROC: 0.63 \n",
      "Epoch[197] Validation MSE: 0.97 Avg Prec: 0.55 acc: 0.46 ROC: 0.63 \n",
      "Epoch[198] Validation MSE: 0.97 Avg Prec: 0.54 acc: 0.46 ROC: 0.63 \n",
      "Epoch[199] Validation MSE: 0.96 Avg Prec: 0.55 acc: 0.46 ROC: 0.63 \n",
      "Epoch[200] Validation MSE: 0.95 Avg Prec: 0.55 acc: 0.46 ROC: 0.63 \n",
      "Epoch[201] Validation MSE: 0.94 Avg Prec: 0.55 acc: 0.47 ROC: 0.63 \n",
      "Epoch[202] Validation MSE: 0.93 Avg Prec: 0.55 acc: 0.46 ROC: 0.63 \n",
      "Epoch[203] Validation MSE: 0.93 Avg Prec: 0.55 acc: 0.45 ROC: 0.63 \n",
      "Epoch[204] Validation MSE: 0.92 Avg Prec: 0.55 acc: 0.46 ROC: 0.64 \n",
      "Epoch[205] Iteration[8400/41] Loss: 0.13\n",
      "Epoch[205] Validation MSE: 0.91 Avg Prec: 0.55 acc: 0.46 ROC: 0.64 \n",
      "Epoch[206] Validation MSE: 0.90 Avg Prec: 0.55 acc: 0.47 ROC: 0.64 \n",
      "Epoch[207] Validation MSE: 0.90 Avg Prec: 0.55 acc: 0.47 ROC: 0.64 \n",
      "Epoch[208] Validation MSE: 0.89 Avg Prec: 0.55 acc: 0.47 ROC: 0.64 \n",
      "Epoch[209] Validation MSE: 0.88 Avg Prec: 0.55 acc: 0.48 ROC: 0.64 \n",
      "Epoch[210] Validation MSE: 0.88 Avg Prec: 0.55 acc: 0.49 ROC: 0.64 \n",
      "Epoch[211] Validation MSE: 0.87 Avg Prec: 0.55 acc: 0.48 ROC: 0.64 \n",
      "Epoch[212] Validation MSE: 0.87 Avg Prec: 0.56 acc: 0.48 ROC: 0.64 \n",
      "Epoch[213] Validation MSE: 0.86 Avg Prec: 0.56 acc: 0.48 ROC: 0.64 \n",
      "Epoch[214] Validation MSE: 0.85 Avg Prec: 0.56 acc: 0.48 ROC: 0.64 \n",
      "Epoch[215] Iteration[8800/41] Loss: 0.15\n",
      "Epoch[215] Validation MSE: 0.85 Avg Prec: 0.55 acc: 0.48 ROC: 0.64 \n",
      "Epoch[216] Validation MSE: 0.84 Avg Prec: 0.55 acc: 0.49 ROC: 0.64 \n",
      "Epoch[217] Validation MSE: 0.84 Avg Prec: 0.55 acc: 0.49 ROC: 0.64 \n",
      "Epoch[218] Validation MSE: 0.83 Avg Prec: 0.56 acc: 0.49 ROC: 0.64 \n",
      "Epoch[219] Validation MSE: 0.83 Avg Prec: 0.56 acc: 0.49 ROC: 0.64 \n",
      "Epoch[220] Validation MSE: 0.82 Avg Prec: 0.56 acc: 0.49 ROC: 0.64 \n",
      "Epoch[221] Validation MSE: 0.82 Avg Prec: 0.55 acc: 0.49 ROC: 0.64 \n",
      "Epoch[222] Validation MSE: 0.82 Avg Prec: 0.55 acc: 0.50 ROC: 0.64 \n",
      "Epoch[223] Validation MSE: 0.81 Avg Prec: 0.55 acc: 0.50 ROC: 0.65 \n",
      "Epoch[224] Validation MSE: 0.81 Avg Prec: 0.55 acc: 0.50 ROC: 0.65 \n",
      "Epoch[225] Iteration[9200/41] Loss: 0.12\n",
      "Epoch[225] Validation MSE: 0.80 Avg Prec: 0.55 acc: 0.51 ROC: 0.65 \n",
      "Epoch[226] Validation MSE: 0.80 Avg Prec: 0.55 acc: 0.51 ROC: 0.65 \n",
      "Epoch[227] Validation MSE: 0.80 Avg Prec: 0.55 acc: 0.51 ROC: 0.65 \n",
      "Epoch[228] Validation MSE: 0.79 Avg Prec: 0.55 acc: 0.51 ROC: 0.65 \n",
      "Epoch[229] Validation MSE: 0.79 Avg Prec: 0.55 acc: 0.51 ROC: 0.65 \n",
      "Epoch[230] Validation MSE: 0.78 Avg Prec: 0.55 acc: 0.49 ROC: 0.65 \n",
      "Epoch[231] Validation MSE: 0.78 Avg Prec: 0.55 acc: 0.49 ROC: 0.65 \n",
      "Epoch[232] Validation MSE: 0.78 Avg Prec: 0.55 acc: 0.49 ROC: 0.65 \n",
      "Epoch[233] Validation MSE: 0.78 Avg Prec: 0.55 acc: 0.49 ROC: 0.65 \n",
      "Epoch[234] Validation MSE: 0.77 Avg Prec: 0.55 acc: 0.49 ROC: 0.65 \n",
      "Epoch[235] Iteration[9600/41] Loss: 0.14\n",
      "Epoch[235] Validation MSE: 0.77 Avg Prec: 0.55 acc: 0.49 ROC: 0.65 \n",
      "Epoch[236] Validation MSE: 0.77 Avg Prec: 0.56 acc: 0.49 ROC: 0.65 \n",
      "Epoch[237] Validation MSE: 0.76 Avg Prec: 0.55 acc: 0.49 ROC: 0.65 \n",
      "Epoch[238] Validation MSE: 0.76 Avg Prec: 0.56 acc: 0.49 ROC: 0.65 \n",
      "Epoch[239] Validation MSE: 0.76 Avg Prec: 0.56 acc: 0.49 ROC: 0.65 \n",
      "Epoch[240] Validation MSE: 0.76 Avg Prec: 0.56 acc: 0.49 ROC: 0.65 \n",
      "Epoch[241] Validation MSE: 0.75 Avg Prec: 0.55 acc: 0.50 ROC: 0.65 \n",
      "Epoch[242] Validation MSE: 0.75 Avg Prec: 0.55 acc: 0.50 ROC: 0.65 \n",
      "Epoch[243] Validation MSE: 0.75 Avg Prec: 0.55 acc: 0.51 ROC: 0.65 \n",
      "Epoch[244] Iteration[10000/41] Loss: 0.13\n",
      "Epoch[244] Validation MSE: 0.75 Avg Prec: 0.55 acc: 0.51 ROC: 0.65 \n",
      "Epoch[245] Validation MSE: 0.75 Avg Prec: 0.55 acc: 0.51 ROC: 0.65 \n",
      "Epoch[246] Validation MSE: 0.74 Avg Prec: 0.55 acc: 0.51 ROC: 0.65 \n",
      "Epoch[247] Validation MSE: 0.74 Avg Prec: 0.55 acc: 0.51 ROC: 0.65 \n",
      "Epoch[248] Validation MSE: 0.74 Avg Prec: 0.55 acc: 0.51 ROC: 0.65 \n",
      "Epoch[249] Validation MSE: 0.74 Avg Prec: 0.55 acc: 0.52 ROC: 0.65 \n",
      "Epoch[250] Validation MSE: 0.74 Avg Prec: 0.55 acc: 0.53 ROC: 0.65 \n",
      "Epoch[251] Validation MSE: 0.73 Avg Prec: 0.55 acc: 0.53 ROC: 0.65 \n",
      "Epoch[252] Validation MSE: 0.73 Avg Prec: 0.55 acc: 0.53 ROC: 0.65 \n",
      "Epoch[253] Validation MSE: 0.73 Avg Prec: 0.55 acc: 0.53 ROC: 0.65 \n",
      "Epoch[254] Iteration[10400/41] Loss: 0.14\n",
      "Epoch[254] Validation MSE: 0.73 Avg Prec: 0.55 acc: 0.53 ROC: 0.65 \n",
      "Epoch[255] Validation MSE: 0.73 Avg Prec: 0.55 acc: 0.53 ROC: 0.65 \n",
      "Epoch[256] Validation MSE: 0.73 Avg Prec: 0.55 acc: 0.53 ROC: 0.66 \n",
      "Epoch[257] Validation MSE: 0.73 Avg Prec: 0.55 acc: 0.53 ROC: 0.66 \n",
      "Epoch[258] Validation MSE: 0.73 Avg Prec: 0.55 acc: 0.53 ROC: 0.66 \n",
      "Epoch[259] Validation MSE: 0.72 Avg Prec: 0.55 acc: 0.54 ROC: 0.66 \n",
      "Epoch[260] Validation MSE: 0.72 Avg Prec: 0.55 acc: 0.54 ROC: 0.66 \n",
      "Epoch[261] Validation MSE: 0.72 Avg Prec: 0.55 acc: 0.54 ROC: 0.65 \n",
      "Epoch[262] Validation MSE: 0.72 Avg Prec: 0.55 acc: 0.55 ROC: 0.65 \n",
      "Epoch[263] Validation MSE: 0.72 Avg Prec: 0.55 acc: 0.55 ROC: 0.65 \n",
      "Epoch[264] Iteration[10800/41] Loss: 0.12\n",
      "Epoch[264] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.55 ROC: 0.65 \n",
      "Epoch[265] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.55 ROC: 0.65 \n",
      "Epoch[266] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.55 ROC: 0.65 \n",
      "Epoch[267] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[268] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[269] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[270] Validation MSE: 0.71 Avg Prec: 0.55 acc: 0.55 ROC: 0.66 \n",
      "Epoch[271] Validation MSE: 0.71 Avg Prec: 0.55 acc: 0.55 ROC: 0.66 \n",
      "Epoch[272] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.55 ROC: 0.66 \n",
      "Epoch[273] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.55 ROC: 0.66 \n",
      "Epoch[274] Iteration[11200/41] Loss: 0.13\n",
      "Epoch[274] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.55 ROC: 0.66 \n",
      "Epoch[275] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.55 ROC: 0.66 \n",
      "Epoch[276] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.54 ROC: 0.66 \n",
      "Epoch[277] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.54 ROC: 0.66 \n",
      "Epoch[278] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.55 ROC: 0.66 \n",
      "Epoch[279] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.55 ROC: 0.66 \n",
      "Epoch[280] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.55 ROC: 0.66 \n",
      "Epoch[281] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.55 ROC: 0.66 \n",
      "Epoch[282] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.66 \n",
      "Epoch[283] Iteration[11600/41] Loss: 0.13\n",
      "Epoch[283] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.66 \n",
      "Epoch[284] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.66 \n",
      "Epoch[285] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[286] Validation MSE: 0.71 Avg Prec: 0.55 acc: 0.56 ROC: 0.65 \n",
      "Epoch[287] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[288] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[289] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[290] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[291] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[292] Validation MSE: 0.71 Avg Prec: 0.55 acc: 0.56 ROC: 0.65 \n",
      "Epoch[293] Iteration[12000/41] Loss: 0.12\n",
      "Epoch[293] Validation MSE: 0.71 Avg Prec: 0.55 acc: 0.56 ROC: 0.65 \n",
      "Epoch[294] Validation MSE: 0.71 Avg Prec: 0.55 acc: 0.56 ROC: 0.65 \n",
      "Epoch[295] Validation MSE: 0.71 Avg Prec: 0.55 acc: 0.56 ROC: 0.65 \n",
      "Epoch[296] Validation MSE: 0.71 Avg Prec: 0.55 acc: 0.56 ROC: 0.65 \n",
      "Epoch[297] Validation MSE: 0.71 Avg Prec: 0.55 acc: 0.56 ROC: 0.65 \n",
      "Epoch[298] Validation MSE: 0.71 Avg Prec: 0.55 acc: 0.56 ROC: 0.65 \n",
      "Epoch[299] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[300] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[301] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[302] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[303] Iteration[12400/41] Loss: 0.12\n",
      "Epoch[303] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.55 ROC: 0.65 \n",
      "Epoch[304] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.55 ROC: 0.65 \n",
      "Epoch[305] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[306] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[307] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[308] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[309] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[310] Validation MSE: 0.71 Avg Prec: 0.54 acc: 0.56 ROC: 0.65 \n",
      "Epoch[311] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.55 ROC: 0.65 \n",
      "Epoch[312] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.55 ROC: 0.65 \n",
      "Epoch[313] Iteration[12800/41] Loss: 0.12\n",
      "Epoch[313] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[314] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[315] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[316] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[317] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[318] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[319] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[320] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[321] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[322] Iteration[13200/41] Loss: 0.13\n",
      "Epoch[322] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[323] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[324] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[325] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[326] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[327] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[328] Validation MSE: 0.72 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[329] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[330] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[331] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.54 ROC: 0.65 \n",
      "Epoch[332] Iteration[13600/41] Loss: 0.12\n",
      "Epoch[332] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[333] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[334] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[335] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[336] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[337] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[338] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[339] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[340] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[341] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[342] Iteration[14000/41] Loss: 0.11\n",
      "Epoch[342] Validation MSE: 0.73 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[343] Validation MSE: 0.74 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[344] Validation MSE: 0.74 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[345] Validation MSE: 0.74 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[346] Validation MSE: 0.74 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[347] Validation MSE: 0.74 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[348] Validation MSE: 0.74 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[349] Validation MSE: 0.74 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[350] Validation MSE: 0.74 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[351] Validation MSE: 0.74 Avg Prec: 0.54 acc: 0.53 ROC: 0.65 \n",
      "Epoch[352] Iteration[14400/41] Loss: 0.10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-849873f769af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Engine run is terminating due to exception: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch[%s] Complete. Time taken: %02d:%02d:%02d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current run is terminating due to exception: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate_single_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/__init__.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python deeplearning",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
