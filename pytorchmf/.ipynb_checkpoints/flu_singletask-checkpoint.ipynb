{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import itertools\n",
    "from make_matrix import *\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('flu_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>virusUprot</th>\n",
       "      <th>humanUprot</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P03433</td>\n",
       "      <td>P49736</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P03433</td>\n",
       "      <td>P15311</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>P03433</td>\n",
       "      <td>P11142</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>P03433</td>\n",
       "      <td>Q86U42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>P03433</td>\n",
       "      <td>P33992</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 virusUprot humanUprot  edge\n",
       "0           0     P03433     P49736   1.0\n",
       "1           1     P03433     P15311   0.0\n",
       "2           2     P03433     P11142   0.0\n",
       "3           3     P03433     Q86U42   0.0\n",
       "4           4     P03433     P33992   1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = df['virusUprot'].unique()\n",
    "hs = df['humanUprot'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>virusUprot</th>\n",
       "      <th>humanUprot</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P03433</td>\n",
       "      <td>P49736</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P03433</td>\n",
       "      <td>P15311</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>P03433</td>\n",
       "      <td>P11142</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>P03433</td>\n",
       "      <td>Q86U42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>P03433</td>\n",
       "      <td>P33992</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 virusUprot humanUprot  edge\n",
       "0           0     P03433     P49736   1.0\n",
       "1           1     P03433     P15311   0.0\n",
       "2           2     P03433     P11142   0.0\n",
       "3           3     P03433     Q86U42   0.0\n",
       "4           4     P03433     P33992   1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.sort()\n",
    "hs.sort()\n",
    "vs_map = {v:i for i,v in enumerate(vs)}\n",
    "hs_map = {h:i for i, h in enumerate(hs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>virusUprot</th>\n",
       "      <th>humanUprot</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>946</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>577</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>1785</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>807</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  virusUprot  humanUprot  edge\n",
       "0           0          52         946   1.0\n",
       "1           1          52         634   0.0\n",
       "2           2          52         577   0.0\n",
       "3           3          52        1785   0.0\n",
       "4           4          52         807   1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.virusUprot = df.virusUprot.apply(lambda x : vs_map[x])\n",
    "df.humanUprot = df.humanUprot.apply(lambda x : hs_map[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018504970365673678"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['edge'] == 1]) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(zip(df.virusUprot.values, df.humanUprot.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['edge'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_torch(arr, dtype):\n",
    "    t =  torch.from_numpy(np.array(arr)).type(dtype).to(device)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = TensorDataset(arr_to_torch(X_train, torch.long), arr_to_torch(y_train, torch.float32))\n",
    "train_loader = DataLoader(train_dset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dset = TensorDataset(arr_to_torch(X_val, torch.long), arr_to_torch(y_val, torch.float32))\n",
    "val_loader = DataLoader(val_dset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset = TensorDataset(arr_to_torch(X_test, torch.long), arr_to_torch(y_test, torch.float32))\n",
    "test_loader = DataLoader(test_dset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularize(array):\n",
    "    loss = torch.sum(array ** 2.0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, n_virus, n_human, k=18, c_vector=1.0, c_bias=1.0, writer=None):\n",
    "        super(MF, self).__init__()\n",
    "        self.writer = writer\n",
    "        self.k = k\n",
    "        self.n_virus = n_virus\n",
    "        self.n_human = n_human\n",
    "        self.c_bias = c_bias\n",
    "        self.c_vector = c_vector\n",
    "        \n",
    "        self.virus = nn.Embedding(n_virus, k)\n",
    "        self.human = nn.Embedding(n_human, k)\n",
    "        \n",
    "        # We've added new terms here:\n",
    "        self.bias_virus = nn.Embedding(n_virus, 1)\n",
    "        self.bias_human = nn.Embedding(n_human, 1)\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "        \n",
    "#         self.affine = nn.Linear(in_features=self.k, out_features=1)\n",
    "#         self.logistic = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, train_x):\n",
    "        virus_id = train_x[:, 0]\n",
    "        human_id = train_x[:, 1]\n",
    "        vector_virus = self.virus(virus_id)\n",
    "        vector_human = self.human(human_id)\n",
    "        \n",
    "        # Pull out biases\n",
    "        bias_virus = self.bias_virus(virus_id).squeeze()\n",
    "        bias_human = self.bias_human(human_id).squeeze()\n",
    "        biases = (self.bias + bias_virus + bias_human)\n",
    "        \n",
    "        ui_interaction = torch.sum(vector_virus * vector_human, dim=1)\n",
    "        \n",
    "        prediction = ui_interaction + biases\n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "#         loss_mse = F.binary_cross_entropy_with_logits(prediction, target.squeeze())\n",
    "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
    "    \n",
    "        # Add new regularization to the biases\n",
    "        prior_bias_virus =  l2_regularize(self.bias_virus.weight) * self.c_bias\n",
    "        prior_bias_human = l2_regularize(self.bias_human.weight) * self.c_bias\n",
    "        \n",
    "        prior_virus =  l2_regularize(self.virus.weight.data) * self.c_vector\n",
    "        prior_human = l2_regularize(self.human.weight.data) * self.c_vector\n",
    "        total = loss_mse + prior_virus + prior_human + prior_bias_virus + prior_bias_human\n",
    "        return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Loss, Accuracy, Precision, Recall\n",
    "from tensorboardX import SummaryWriter\n",
    "from ignite.metrics import MeanSquaredError, Loss\n",
    "from ignite.contrib.metrics import AveragePrecision, ROC_AUC\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/simple_mf_02_bias_2019-05-18_21:33:06.870381\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "lr = 1e-3\n",
    "k =20\n",
    "# New parameter for regularizing bias\n",
    "c_bias = 1e-4\n",
    "c_vector = 1e-4\n",
    "batchsize = bs\n",
    "log_dir = 'runs/simple_mf_02_bias_' + str(datetime.now()).replace(' ', '_')\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MF(\n",
       "  (virus): Embedding(203, 20)\n",
       "  (human): Embedding(2727, 20)\n",
       "  (bias_virus): Embedding(203, 1)\n",
       "  (bias_human): Embedding(2727, 1)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "# crit = nn.MSELoss()\n",
    "\n",
    "model = MF(len(vs_map), len(hs_map), writer=writer, k=k, c_bias=c_bias, c_vector=c_vector)\n",
    "crit = model.loss\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "trainer = create_supervised_trainer(model, optimizer, model.loss)\n",
    "metrics = {'loss': Loss(crit), 'ap': AveragePrecision(), \"acc\": Accuracy(), \"roc\": ROC_AUC()}\n",
    "evaluator = create_supervised_evaluator(model, metrics=metrics)\n",
    "\n",
    "def log_training_loss(engine, log_interval=400):\n",
    "    epoch = engine.state.epoch\n",
    "    itr = engine.state.iteration\n",
    "    fmt = \"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
    "    msg = fmt.format(epoch, itr, len(train_loader), engine.state.output)\n",
    "    model.itr = itr\n",
    "    if itr % log_interval == 0:\n",
    "        print(msg)\n",
    "#         metrics = trainer.state.metrics\n",
    "#         mse = metrics['loss']\n",
    "#         avg_precision = metrics['ap']\n",
    "#         accuracy = metrics['acc']\n",
    "#         roc = metrics['roc']\n",
    "#         writer.add_scalar(\"training/mse\", mse, engine.state.epoch)\n",
    "#         writer.add_scalar(\"training/ap\", avg_precision, engine.state.epoch)\n",
    "#         writer.add_scalar(\"training/accuracy\", accuracy, engine.state.epoch)\n",
    "#         writer.add_scalar(\"training/roc\", roc, engine.state.epoch)\n",
    "\n",
    "trainer.add_event_handler(event_name=Events.ITERATION_COMPLETED, handler=log_training_loss)\n",
    "\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    mse = metrics['loss']\n",
    "    avg_precision = metrics['ap']\n",
    "    accuracy = metrics['acc']\n",
    "    roc = metrics['roc']\n",
    "    print(\"Epoch[{}] Validation MSE: {:.2f} Avg Prec: {:.2f} acc: {:.2f} ROC: {:.2f} \"\n",
    "          .format(engine.state.epoch, mse, avg_precision, accuracy, roc))\n",
    "    writer.add_scalar(\"validation/mse\", mse, engine.state.epoch)\n",
    "    writer.add_scalar(\"validation/avg_precision\", avg_precision, engine.state.epoch)\n",
    "    writer.add_scalar(\"validation/accuracy\", accuracy, engine.state.epoch)\n",
    "    writer.add_scalar(\"validation/roc\", roc, engine.state.epoch)\n",
    "\n",
    "    \n",
    "def log_test_results(engine):\n",
    "    evaluator.run(test_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    mse = metrics['loss']\n",
    "    avg_precision = metrics['ap']\n",
    "    accuracy = metrics['acc']\n",
    "    roc = metrics['roc']\n",
    "\n",
    "    print(\"TEST: Epoch[{}] Validation MSE: {:.2f} Avg Prec: {:.2f} acc: {:.2f} ROC: {:.2f}\"\n",
    "          .format(engine.state.epoch, mse, avg_precision, accuracy, roc))\n",
    "\n",
    "\n",
    "trainer.add_event_handler(event_name=Events.EPOCH_COMPLETED, handler=log_validation_results)\n",
    "trainer.add_event_handler(event_name=Events.COMPLETED, handler=log_test_results)\n",
    "\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MF(\n",
       "  (virus): Embedding(203, 20)\n",
       "  (human): Embedding(2727, 20)\n",
       "  (bias_virus): Embedding(203, 1)\n",
       "  (bias_human): Embedding(2727, 1)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Iteration[400/11072] Loss: 21.43\n",
      "Epoch[1] Iteration[800/11072] Loss: 34.17\n",
      "Epoch[1] Iteration[1200/11072] Loss: 23.30\n",
      "Epoch[1] Iteration[1600/11072] Loss: 22.02\n",
      "Epoch[1] Iteration[2000/11072] Loss: 15.63\n",
      "Epoch[1] Iteration[2400/11072] Loss: 11.93\n",
      "Epoch[1] Iteration[2800/11072] Loss: 17.66\n",
      "Epoch[1] Iteration[3200/11072] Loss: 20.70\n",
      "Epoch[1] Iteration[3600/11072] Loss: 12.47\n",
      "Epoch[1] Iteration[4000/11072] Loss: 9.72\n",
      "Epoch[1] Iteration[4400/11072] Loss: 12.59\n",
      "Epoch[1] Iteration[4800/11072] Loss: 17.64\n",
      "Epoch[1] Iteration[5200/11072] Loss: 9.59\n",
      "Epoch[1] Iteration[5600/11072] Loss: 13.19\n",
      "Epoch[1] Iteration[6000/11072] Loss: 11.99\n",
      "Epoch[1] Iteration[6400/11072] Loss: 12.49\n",
      "Epoch[1] Iteration[6800/11072] Loss: 8.99\n",
      "Epoch[1] Iteration[7200/11072] Loss: 11.48\n",
      "Epoch[1] Iteration[7600/11072] Loss: 9.27\n",
      "Epoch[1] Iteration[8000/11072] Loss: 7.68\n",
      "Epoch[1] Iteration[8400/11072] Loss: 7.80\n",
      "Epoch[1] Iteration[8800/11072] Loss: 7.22\n",
      "Epoch[1] Iteration[9200/11072] Loss: 7.29\n",
      "Epoch[1] Iteration[9600/11072] Loss: 6.78\n",
      "Epoch[1] Iteration[10000/11072] Loss: 6.63\n",
      "Epoch[1] Iteration[10400/11072] Loss: 6.77\n",
      "Epoch[1] Iteration[10800/11072] Loss: 6.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roncal/.conda/envs/deeplearning/lib/python3.6/site-packages/sklearn/metrics/ranking.py:526: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/home/roncal/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/metrics/epoch_metric.py:76: RuntimeWarning: Probably, there can be a problem with `compute_fn`:\n",
      " Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Validation MSE: 5.90 Avg Prec: 0.02 acc: 0.33 ROC: 0.53 \n",
      "Epoch[2] Iteration[11200/11072] Loss: 6.50\n",
      "Epoch[2] Iteration[11600/11072] Loss: 4.94\n",
      "Epoch[2] Iteration[12000/11072] Loss: 5.15\n",
      "Epoch[2] Iteration[12400/11072] Loss: 4.72\n",
      "Epoch[2] Iteration[12800/11072] Loss: 4.65\n",
      "Epoch[2] Iteration[13200/11072] Loss: 5.13\n",
      "Epoch[2] Iteration[13600/11072] Loss: 4.35\n",
      "Epoch[2] Iteration[14000/11072] Loss: 4.44\n",
      "Epoch[2] Iteration[14400/11072] Loss: 4.19\n",
      "Epoch[2] Iteration[14800/11072] Loss: 4.23\n",
      "Epoch[2] Iteration[15200/11072] Loss: 4.01\n",
      "Epoch[2] Iteration[15600/11072] Loss: 3.88\n",
      "Epoch[2] Iteration[16000/11072] Loss: 3.95\n",
      "Epoch[2] Iteration[16400/11072] Loss: 3.73\n",
      "Epoch[2] Iteration[16800/11072] Loss: 3.79\n",
      "Epoch[2] Iteration[17200/11072] Loss: 3.76\n",
      "Epoch[2] Iteration[17600/11072] Loss: 3.63\n",
      "Epoch[2] Iteration[18000/11072] Loss: 3.61\n",
      "Epoch[2] Iteration[18400/11072] Loss: 3.58\n",
      "Epoch[2] Iteration[18800/11072] Loss: 3.51\n",
      "Epoch[2] Iteration[19200/11072] Loss: 3.52\n",
      "Epoch[2] Iteration[19600/11072] Loss: 3.50\n",
      "Epoch[2] Iteration[20000/11072] Loss: 3.49\n",
      "Epoch[2] Iteration[20400/11072] Loss: 3.45\n",
      "Epoch[2] Iteration[20800/11072] Loss: 3.44\n",
      "Epoch[2] Iteration[21200/11072] Loss: 3.43\n",
      "Epoch[2] Iteration[21600/11072] Loss: 3.42\n",
      "Epoch[2] Iteration[22000/11072] Loss: 3.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roncal/.conda/envs/deeplearning/lib/python3.6/site-packages/sklearn/metrics/ranking.py:526: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/home/roncal/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/metrics/epoch_metric.py:76: RuntimeWarning: Probably, there can be a problem with `compute_fn`:\n",
      " Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2] Validation MSE: 3.43 Avg Prec: 0.08 acc: 0.97 ROC: 0.78 \n",
      "Epoch[3] Iteration[22400/11072] Loss: 3.40\n",
      "Epoch[3] Iteration[22800/11072] Loss: 3.39\n",
      "Epoch[3] Iteration[23200/11072] Loss: 3.46\n",
      "Epoch[3] Iteration[23600/11072] Loss: 3.38\n",
      "Epoch[3] Iteration[24000/11072] Loss: 3.37\n",
      "Epoch[3] Iteration[24400/11072] Loss: 3.36\n",
      "Epoch[3] Iteration[24800/11072] Loss: 3.35\n",
      "Epoch[3] Iteration[25200/11072] Loss: 3.36\n",
      "Epoch[3] Iteration[25600/11072] Loss: 3.36\n",
      "Epoch[3] Iteration[26000/11072] Loss: 3.34\n",
      "Epoch[3] Iteration[26400/11072] Loss: 3.31\n",
      "Epoch[3] Iteration[26800/11072] Loss: 3.31\n",
      "Epoch[3] Iteration[27200/11072] Loss: 3.29\n",
      "Epoch[3] Iteration[27600/11072] Loss: 3.28\n",
      "Epoch[3] Iteration[28000/11072] Loss: 3.27\n",
      "Epoch[3] Iteration[28400/11072] Loss: 3.26\n",
      "Epoch[3] Iteration[28800/11072] Loss: 3.30\n",
      "Epoch[3] Iteration[29200/11072] Loss: 3.26\n",
      "Epoch[3] Iteration[29600/11072] Loss: 3.24\n",
      "Epoch[3] Iteration[30000/11072] Loss: 3.22\n",
      "Epoch[3] Iteration[30400/11072] Loss: 3.25\n",
      "Epoch[3] Iteration[30800/11072] Loss: 3.19\n",
      "Epoch[3] Iteration[31200/11072] Loss: 3.17\n",
      "Epoch[3] Iteration[31600/11072] Loss: 3.16\n",
      "Epoch[3] Iteration[32000/11072] Loss: 3.18\n",
      "Epoch[3] Iteration[32400/11072] Loss: 3.13\n",
      "Epoch[3] Iteration[32800/11072] Loss: 3.14\n",
      "Epoch[3] Iteration[33200/11072] Loss: 3.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roncal/.conda/envs/deeplearning/lib/python3.6/site-packages/sklearn/metrics/ranking.py:526: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n",
      "/home/roncal/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/metrics/epoch_metric.py:76: RuntimeWarning: Probably, there can be a problem with `compute_fn`:\n",
      " Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3] Validation MSE: 3.12 Avg Prec: 0.16 acc: 0.98 ROC: 0.82 \n",
      "Epoch[4] Iteration[33600/11072] Loss: 3.16\n",
      "Epoch[4] Iteration[34000/11072] Loss: 3.10\n",
      "Epoch[4] Iteration[34400/11072] Loss: 3.09\n",
      "Epoch[4] Iteration[34800/11072] Loss: 3.09\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-849873f769af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Engine run is terminating due to exception: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch[%s] Complete. Time taken: %02d:%02d:%02d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current run is terminating due to exception: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_terminate_single_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/ignite/engine/__init__.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deeplearning/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mbias_correction2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python deeplearning",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
