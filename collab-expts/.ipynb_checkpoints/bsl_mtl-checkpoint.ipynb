{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BSL-MTl\n",
    "\n",
    "### Christian Roncal, CMSC499-lrgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far:\n",
    "1. Looked into collaborative filtering with SGD\n",
    "1. Made data easier to work with\n",
    "\n",
    "Now:\n",
    "Implement bilinear sparse low rank multitask model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much we want to learn embeddings $U, V, S$ in the function:\n",
    "$$f_t(x_{ti}, y_{ij}) = x^T_{ti}H_{t}y_{tj} \\text{ where }H_t = \\mu_tUV^T + (1 - \\mu_t)S_t$$\n",
    "\n",
    "which represents an individual link prediction for a task t, given human protein features $x$ and viral protein features $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives the objective loss function:\n",
    "$$\\mathcal{L}(U, V, \\{S_t\\}) = \\frac{1}{N} \\sum_{t = 1}^{T}\\sum_{(i,j) \\in \\Omega_t} c^t_{ij} l(M_{ij}, x^T_{ti}H_{t}y_{tj}) +  \\lambda(||U||^2_F + ||V||^2_F) | \\sum_{t=1}^T \\sigma_t||S_t||_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to optimize this with ALS / Block coordinate descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the following:\n",
    "    $$ \\frac{\\partial{\\mathcal{L}}}{\\partial{V}}, \\frac{\\partial{\\mathcal{L}}}{\\partial{U}},, \\frac{\\partial{\\mathcal{L}}}{\\partial{S}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, $\\frac{\\partial{\\mathcal{L}}}{\\partial{U}}$:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\frac{\\partial{\\mathcal{L}}}{\\partial{U}} &= \\frac{1}{N} \\sum_{t = 1}^{T}\\sum_{(i,j) \\in \\Omega_t} c^t_{ij} \\frac{\\partial{}}{\\partial{U}}(l(M_{ij}, x^T_{ti}H_{t}y_{tj})) + 2\\lambda||U||_F\\\\\n",
    "\\frac{\\partial{\\mathcal{L}}}{\\partial{U}}(l(M_{ij}, x^T_{ti}H_{t}y_{tj})) &= \\frac{\\partial{}}{\\partial{U}} ((M_{ij} - x^T_{ti}H_{t}y_{tj})^2) * \\frac{\\partial{}}{\\partial{U}} (l(M_{ij} - x^T_{ti}H_{t}y_{tj})) & \\text{chain rule}\\\\\n",
    "\\frac{\\partial{\\mathcal{L}}}{\\partial{U}} & = \\frac{1}{N} \\sum_{t = 1}^{T}\\sum_{(i,j) \\in \\Omega_t} c^t_{ij} 2((M_{ij} - x^T_{ti}H_{t}y_{tj}))*(-x_{t_i}(\\mu_tV^T)y_{t_j})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah... I gave up deriving these. I'm just going to see how the code from the paper calculated the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSL_MTL():\n",
    "    \n",
    "    def __init__(self):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
