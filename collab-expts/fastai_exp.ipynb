{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "from fastaiv07.learner import *\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make random data for testing\n",
    "'''\n",
    "def make_colab_data(n, m, max_mIJ = 5):\n",
    "    ratings = np.random.randint(max_mIJ, size=(n,m))\n",
    "    \n",
    "    data_dict = {'row':[], 'col':[], 'm_IJ':[]}\n",
    "    \n",
    "    for row in range(n):\n",
    "        for col in range(m):\n",
    "            data_dict['row'].append(row)\n",
    "            data_dict['col'].append(col)\n",
    "            data_dict['m_IJ'].append(ratings[row,col])\n",
    "    \n",
    "    return pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestData(data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        nonzero_entries = df.loc[df['m_IJ'] > 0].values\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.vals)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self.index_pairs[index]\n",
    "        y = self.vals[index]\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDot(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors=3):\n",
    "        super().__init__()\n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        self.u.weight.data.uniform_(0,0.05)\n",
    "        self.m.weight.data.uniform_(0,0.05)\n",
    "        \n",
    "    def forward(self, indices):\n",
    "        row,col = indices[0],indices[1]\n",
    "        u,m = self.u(Variable(row)),self.m(Variable(col))\n",
    "        return (u*m).sum(1).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb(ni,nf):\n",
    "    e = nn.Embedding(ni, nf)\n",
    "    e.weight.data.uniform_(-0.01,0.01)\n",
    "    return e\n",
    "\n",
    "class EmbeddingDotBias(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors=10):\n",
    "        super().__init__()\n",
    "        (self.u, self.m, self.ub, self.mb) = [get_emb(*o) for o in [\n",
    "            (n_users, n_factors), (n_movies, n_factors), (n_users,1), (n_movies,1)\n",
    "        ]]\n",
    "        \n",
    "    def forward(self, indices):\n",
    "        users,movies = indices[0],indices[1]\n",
    "        um = (self.u(users)* self.m(movies)).sum(1)\n",
    "        res = um + self.ub(users).squeeze() + self.mb(movies).squeeze()\n",
    "        res = torch.sigmoid(res) * (5-1) + 1\n",
    "        return res.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors=15, nh=10, p1=0.05, p2=0.5):\n",
    "        super().__init__()\n",
    "        (self.u, self.m) = [get_emb(*o) for o in [\n",
    "            (n_users, n_factors), (n_movies, n_factors)]]\n",
    "        self.lin1 = nn.Linear(n_factors*2, nh)\n",
    "        self.lin2 = nn.Linear(nh, 1)\n",
    "        self.drop1 = nn.Dropout(p1)\n",
    "        self.drop2 = nn.Dropout(p2)\n",
    "        \n",
    "    def forward(self, indices):\n",
    "        users,movies = indices[0],indices[1]\n",
    "        x = self.drop1(torch.cat([self.u(users),self.m(movies)], dim=1))\n",
    "        x = self.drop2(F.relu(self.lin1(x)))\n",
    "        return torch.sigmoid(self.lin2(x)) * (5-0+1) + 0-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 10\n",
    "def train(model, opt, epochs=1):\n",
    "    best_acc = -1\n",
    "\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for c, (x, y) in enumerate(loader):\n",
    "            model.train()\n",
    "\n",
    "            pred = model(x)\n",
    "\n",
    "#             criterion = nn.MSELoss()\n",
    "            loss = F.mse_loss(pred, y.float())\n",
    "#             opt.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            opt.step()\n",
    "            \n",
    "\n",
    "            if e % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (e, loss.item()))\n",
    "                acc = check_accuracy_part34(loader, model)\n",
    "                best_acc = acc if acc > best_acc else best_acc\n",
    "            \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "#             x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "#             y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "#             print(x, 'pred: ', scores, 'gt: ', y)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y.long()).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TestData' object has no attribute 'vals'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c05966c032d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_colab_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtestdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# print(df.loc[df['m_IJ'] > 0].values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn)\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b43490430000>\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TestData' object has no attribute 'vals'"
     ]
    }
   ],
   "source": [
    "params = {'batch_size': 1,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "epochs = 10\n",
    "N = 25\n",
    "df = make_colab_data(N,N)\n",
    "testdata = TestData(df)\n",
    "loader = data.DataLoader(testdata, **params)\n",
    "# print(df.loc[df['m_IJ'] > 0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-5\n",
    "model = EmbeddingDotBias(N, N, 20)\n",
    "# model = EmbeddingNet(N, N, n_factors=15)\n",
    "opt = optim.SGD(model.parameters(), 1e-3, weight_decay=wd, momentum=0.9)\n",
    "train(model, opt, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-139859670a0a>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-139859670a0a>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    train(model, opt, epochs=100)check_accuracy_part34(loader, model)\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ", N, n_factors=15)\n",
    "opt = optim.SGD(model.parameters(), 1e-3, weight_decay=wd, momentum=0.9)\n",
    "train(model, opt, epochs=100)check_accuracy_part34(loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 0  2  2]\n",
      " [ 0  3  1]\n",
      " ...\n",
      " [24 19  1]\n",
      " [24 21  2]\n",
      " [24 24  4]]\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['m_IJ'] > 0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
