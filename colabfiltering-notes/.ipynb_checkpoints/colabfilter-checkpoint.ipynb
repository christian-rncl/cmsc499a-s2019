{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering / Low rank matrix factoriaztion\n",
    "## Christian Roncal 499A\n",
    "\n",
    "Demonstration/Study of low rank matrix factorization colab filtering on movielens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as pltf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load / Shape data -- skip\n",
    "\n",
    "Massage data to play with. Create a matrix with rows representing users and cols representing movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratings.csv', 'README.txt', 'tags.csv', 'movies.csv', 'links.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/ml-latest-small/'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple csv files. We're interested in predicting movies and user ratings.\n",
    "Just need ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(path+'/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>110</th>\n",
       "      <th>260</th>\n",
       "      <th>296</th>\n",
       "      <th>318</th>\n",
       "      <th>356</th>\n",
       "      <th>480</th>\n",
       "      <th>527</th>\n",
       "      <th>589</th>\n",
       "      <th>593</th>\n",
       "      <th>2571</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  110   260   296   318   356   480   527   589   593   2571\n",
       "userId                                                             \n",
       "68        2.5   5.0   2.0   3.0   3.5   3.5   4.0   3.5   3.5   4.5\n",
       "274       4.5   3.0   5.0   4.5   4.5   3.5   4.0   4.5   4.0   4.0\n",
       "288       5.0   5.0   5.0   5.0   5.0   2.0   5.0   4.0   5.0   3.0\n",
       "380       4.0   5.0   5.0   3.0   5.0   5.0   NaN   5.0   5.0   4.5\n",
       "414       5.0   5.0   5.0   5.0   5.0   4.0   4.0   5.0   4.0   5.0\n",
       "448       NaN   5.0   5.0   NaN   3.0   3.0   NaN   3.0   5.0   2.0\n",
       "474       3.0   4.0   4.0   5.0   3.0   4.5   5.0   4.0   4.5   4.5\n",
       "599       3.5   5.0   5.0   4.0   3.5   4.0   NaN   4.5   3.0   5.0\n",
       "606       3.5   4.5   5.0   3.5   4.0   2.5   5.0   3.5   4.5   5.0\n",
       "610       4.5   5.0   5.0   3.0   3.0   5.0   3.5   5.0   4.5   5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10 #top N\n",
    "\n",
    "# stolen from: https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb\n",
    "g=ratings_df.groupby('userId')['rating'].count()\n",
    "topUsers=g.sort_values(ascending=False)[:N]\n",
    "\n",
    "g=ratings_df.groupby('movieId')['rating'].count()\n",
    "topMovies=g.sort_values(ascending=False)[:N]\n",
    "\n",
    "top_r = ratings_df.join(topUsers, rsuffix='_r', how='inner', on='userId')\n",
    "top_r = top_r.join(topMovies, rsuffix='_r', how='inner', on='movieId')\n",
    "\n",
    "crosstab = pd.crosstab(top_r.userId, top_r.movieId, top_r.rating, aggfunc=np.sum)\n",
    "crosstab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, let's make it easier to work with by replacing the NaNs with 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>110</th>\n",
       "      <th>260</th>\n",
       "      <th>296</th>\n",
       "      <th>318</th>\n",
       "      <th>356</th>\n",
       "      <th>480</th>\n",
       "      <th>527</th>\n",
       "      <th>589</th>\n",
       "      <th>593</th>\n",
       "      <th>2571</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  110   260   296   318   356   480   527   589   593   2571\n",
       "userId                                                             \n",
       "68        2.5   5.0   2.0   3.0   3.5   3.5   4.0   3.5   3.5   4.5\n",
       "274       4.5   3.0   5.0   4.5   4.5   3.5   4.0   4.5   4.0   4.0\n",
       "288       5.0   5.0   5.0   5.0   5.0   2.0   5.0   4.0   5.0   3.0\n",
       "380       4.0   5.0   5.0   3.0   5.0   5.0   0.0   5.0   5.0   4.5\n",
       "414       5.0   5.0   5.0   5.0   5.0   4.0   4.0   5.0   4.0   5.0\n",
       "448       0.0   5.0   5.0   0.0   3.0   3.0   0.0   3.0   5.0   2.0\n",
       "474       3.0   4.0   4.0   5.0   3.0   4.5   5.0   4.0   4.5   4.5\n",
       "599       3.5   5.0   5.0   4.0   3.5   4.0   0.0   4.5   3.0   5.0\n",
       "606       3.5   4.5   5.0   3.5   4.0   2.5   5.0   3.5   4.5   5.0\n",
       "610       4.5   5.0   5.0   3.0   3.0   5.0   3.5   5.0   4.5   5.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstab = crosstab.fillna(0)\n",
    "crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = crosstab.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Collaborative Filtering through low rank matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Collaborative filtering is an algorithm to learn 'latent' features in an interaction between two things.</mark> It's an algorithm that can discover a pattern or reasoning between interactions. In this toy example, it's the interaction between the top 30 'busiest' users and the top 30 movies from the downloaded dataset.\n",
    "\n",
    "<mark>Ultimately we want to use the learned latent features to predict interactions (nans in the array above or future/unseen interactions).</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low rank matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common way to approach collaborative filtering is through low rank matrix factorization. <mark>Simply put, since we can represent interactions through a matrix, surely we can approximate the matrix by decomposing the matrix based on observed data (non-nans)</mark>:\n",
    "\n",
    "$$M \\approx R*C$$\n",
    "\n",
    "For our case, $M$ are the ratings we're trying to predict, $\\Theta$ are the latent features about the users, and $W$ are the latent features about the movies.\n",
    "\n",
    "It follows that the prediction for some unknown $M_{i,j}$ will be the dot product for the relevant feature vector in $R$ and the relevant feature vector in $C$:\n",
    "$$M_{i,j} = R_i * C_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization/learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As always with anything ML, to learn $\\Theta$ and $W$ we guess and optimize:\n",
    "1. We initialize both matrices randomly/some fancy method\n",
    "1. Learn feature vectors $\\theta_i, w_j$ based on observed data\n",
    "1. Gradient Descent / Optimization algo!!!\n",
    "1. ???\n",
    "1. profit\n",
    "\n",
    "This means we need an optimization objective:\n",
    "$$L(\\Theta, G) = \\sum_{(i,j) \\in \\Omega} l(M_{i,j}, \\theta^T_i*g_j) + bias + \\text{regularization}$$\n",
    "\n",
    "Where $l$ is some loss function. The paper used l1 norm for the loss function, we can try experimenting with both, and maybe some built in pytorch loss functions. bias / regularization can be discussed later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='algo.png' width=500px/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowRankFactorization():\n",
    "    \n",
    "    def __init__(self, n_R, n_C, K, alpha, reg):\n",
    "        '''\n",
    "        n_R: number of rows\n",
    "        n_C: number of cols\n",
    "        K: latent factors dimensionality\n",
    "        reg: regularization strength\n",
    "        alpha: learning rate\n",
    "        '''\n",
    "        self.R = np.random.randn(n_R, K) / K\n",
    "        self.C = np.random.randn(n_C, K) / K\n",
    "        self.R_bias = np.zeros(n_R)\n",
    "        self.C_bias = np.zeros(n_C)\n",
    "        self.reg = reg\n",
    "        self.alpha = alpha\n",
    "        self.F = None\n",
    "    \n",
    "    def forward(self):\n",
    "        self.F = self.R.dot(self.C.T) + (self.R_bias[:,np.newaxis] + self.C_bias[np.newaxis:,])\n",
    "        return np.copy(self.F)\n",
    "    \n",
    "    def mse_loss(self, M):\n",
    "        Z = np.argwhere(M > 0)\n",
    "        loss = 0\n",
    "        \n",
    "        for i, j in Z:\n",
    "            loss += (M[i,j] - self.F[i,j])**2\n",
    "        return np.sqrt(loss)\n",
    "        \n",
    "    def backward(self, M):\n",
    "        Z = np.argwhere(M > 0)\n",
    "        \n",
    "        # sgd\n",
    "        for i, j in Z:\n",
    "            loss = M[i, j] - self.F[i, j]\n",
    "            self.R_bias[i] += self.alpha * (loss - self.reg * self.R_bias[i])\n",
    "            self.C_bias[j] += self.alpha * (loss - self.reg * self.C_bias[j])\n",
    "            \n",
    "            self.R[i, :] += self.alpha * (loss * self.C[j, :] - self.reg * self.R[i, :])\n",
    "            self.C[j, :] += self.alpha * (loss * self.R[i, :] - self.reg * self.C[j, :])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test implementation by trying to overfit a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real: \n",
      "[[4 1 2 2 0 1 3 3 3 1]\n",
      " [0 4 1 3 3 4 0 0 0 3]\n",
      " [4 0 0 1 3 4 0 2 0 3]\n",
      " [1 2 0 0 4 0 2 3 3 1]\n",
      " [0 4 2 0 3 3 0 0 0 2]\n",
      " [2 0 4 0 2 1 3 0 2 3]\n",
      " [0 2 2 0 4 3 1 0 1 1]\n",
      " [4 3 3 3 3 0 4 0 3 1]\n",
      " [4 2 4 3 2 2 0 1 0 2]\n",
      " [0 3 0 1 4 4 0 4 0 2]]\n",
      "pred: \n",
      "[[ 4.034  1.384  1.973  1.975  3.426  0.981  3.154  3.035  2.843  0.612]\n",
      " [ 4.937  4.156  1.11   2.753  3.046  3.966 -1.029  2.09  -0.744  2.978]\n",
      " [ 3.953  4.261 -2.673  1.117  2.992  4.034 -3.939  2.039 -2.53   2.879]\n",
      " [ 1.053  2.082 -2.783  0.305  3.926 -0.275  1.996  2.995  3.032  0.936]\n",
      " [ 4.411  3.597  1.975  2.901  2.978  2.954  0.643  1.978  0.528  2.505]\n",
      " [ 1.984  4.191  3.942  3.997  1.905  1.136  3.088 -0.167  1.996  2.927]\n",
      " [ 6.276  1.847  1.927  2.138  3.808  3.15   1.038  3.9    1.077  1.124]\n",
      " [ 3.779  2.427  3.192  2.982  3.255  1.244  3.738  2.377  3.081  1.536]\n",
      " [ 4.153  2.449  3.921  3.141  1.981  1.848  1.908  0.986  0.904  1.522]\n",
      " [ 5.457  3.019 -1.847  1.025  4.09   3.97  -2.126  3.953 -0.806  1.97 ]]\n",
      "loss:  1.5617710171584132\n"
     ]
    }
   ],
   "source": [
    "R = np.random.randint(5, size=(10,10))\n",
    "model = LowRankFactorization(R.shape[0], R.shape[1], 3, .01, .001)\n",
    "epochs = 1000\n",
    "\n",
    "loss = []\n",
    "for e in range(epochs):\n",
    "    model.forward()\n",
    "    model.backward(R)\n",
    "    loss.append(np.around(model.mse_loss(R), decimals=3))\n",
    "                \n",
    "print(\"real: \")\n",
    "#print_matrix(R)\n",
    "print(R)\n",
    "print(\"pred: \")\n",
    "print(np.around(model.forward(), decimals=3))\n",
    "print(\"loss: \", model.mse_loss(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff155993cf8>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to fit movielens dataset (top 10 viewers/movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real: \n",
      "[[2.5 5.  2.  3.  3.5 3.5 4.  3.5 3.5 4.5]\n",
      " [4.5 3.  5.  4.5 4.5 3.5 4.  4.5 4.  4. ]\n",
      " [5.  5.  5.  5.  5.  2.  5.  4.  5.  3. ]\n",
      " [4.  5.  5.  3.  5.  5.  0.  5.  5.  4.5]\n",
      " [5.  5.  5.  5.  5.  4.  4.  5.  4.  5. ]\n",
      " [0.  5.  5.  0.  3.  3.  0.  3.  5.  2. ]\n",
      " [3.  4.  4.  5.  3.  4.5 5.  4.  4.5 4.5]\n",
      " [3.5 5.  5.  4.  3.5 4.  0.  4.5 3.  5. ]\n",
      " [3.5 4.5 5.  3.5 4.  2.5 5.  3.5 4.5 5. ]\n",
      " [4.5 5.  5.  3.  3.  5.  3.5 5.  4.5 5. ]]\n",
      "pred: \n",
      "[[2.379 4.855 2.5   3.329 2.803 3.592 4.127 3.306 3.499 4.489]\n",
      " [4.67  3.654 5.191 4.454 4.398 3.116 3.71  4.46  3.779 4.06 ]\n",
      " [4.634 4.516 5.182 5.033 5.049 2.154 5.341 3.826 5.007 3.239]\n",
      " [4.085 5.238 5.552 3.249 4.107 4.761 4.616 4.843 4.975 4.591]\n",
      " [4.886 4.533 5.12  5.049 4.68  4.059 4.303 5.004 4.165 5.139]\n",
      " [2.616 4.884 4.748 1.708 3.276 2.872 4.846 3.02  5.168 2.23 ]\n",
      " [3.545 4.918 3.835 4.102 3.771 3.815 4.482 4.075 4.085 4.702]\n",
      " [3.855 4.382 4.346 3.798 3.657 4.289 3.657 4.561 3.632 4.967]\n",
      " [3.74  4.684 4.525 3.82  4.019 3.246 4.633 3.894 4.481 3.832]\n",
      " [3.866 4.843 5.055 3.073 3.62  5.141 3.801 4.972 4.168 5.106]]\n",
      "loss:  3.622482609279756\n"
     ]
    }
   ],
   "source": [
    "model = LowRankFactorization(M.shape[0], M.shape[1], 3, .01, .001)\n",
    "epochs = 150\n",
    "\n",
    "loss = []\n",
    "for e in range(epochs):\n",
    "    model.forward()\n",
    "    model.backward(M)\n",
    "    loss.append(np.around(model.mse_loss(M), decimals=3))\n",
    "\n",
    "print(\"real: \")\n",
    "#print_matrix(R)\n",
    "print(M)\n",
    "print(\"pred: \")\n",
    "print(np.around(model.forward(), decimals=3))\n",
    "print(\"loss: \", model.mse_loss(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff15575dac8>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "http://nyc.lti.cs.cmu.edu/classes/11-741/Papers/gemulla-sigkdd11.pdf\n",
    "https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture25-mf.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import rand as sprand\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Make up some random explicit feedback ratings\n",
    "# and convert to a numpy array\n",
    "n_users = 30\n",
    "n_items = 30\n",
    "ratings = sprand(n_users, n_items, \n",
    "                 density=0.01, format='csr')\n",
    "ratings.data = (np.random.randint(1, 5, \n",
    "                                  size=ratings.nnz)\n",
    "                          .astype(np.float64))\n",
    "ratings = ratings.toarray()\n",
    "\n",
    "ratings = np.random.randint(5, size=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 2, 4, 0],\n",
       "       [2, 1, 1, 4, 4],\n",
       "       [0, 3, 4, 0, 4],\n",
       "       [2, 1, 4, 3, 3],\n",
       "       [2, 3, 2, 0, 4]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        return (self.user_factors(user) * self.item_factors(item)).sum(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasedMatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        self.user_biases = torch.nn.Embedding(n_users, \n",
    "                                              1,\n",
    "                                              sparse=True)\n",
    "        self.item_biases = torch.nn.Embedding(n_items,\n",
    "                                              1,\n",
    "                                              sparse=True)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        pred = self.user_biases(user) + self.item_biases(item)\n",
    "        pred += (self.user_factors(user) * self.item_factors(item)).sum(1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.nn.Embedding(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "    \n",
    "    '''\n",
    "    takes nonzeros\n",
    "    '''\n",
    "    def forward(self, X, Y):\n",
    "        return (x - y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    " model = MatrixFactorization(n_users, n_items, n_factors=3)\n",
    "#model = BiasedMatrixFactorization(n_users, n_items, n_factors=3)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=1e-3) # learning rate\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort our data\n",
    "rows, cols = ratings.nonzero()\n",
    "nonzero_shape = ratings.nonzer().shape\n",
    "\n",
    "for e in range(epochs):\n",
    "    gt = np.zeros()\n",
    "    pred = np.zeros\n",
    "    for row, col in zip(*(rows, cols)):\n",
    "        # Turn data into variables\n",
    "        rating = Variable(torch.FloatTensor([ratings[row, col]]))\n",
    "        row = Variable(torch.LongTensor([np.long(row)]))\n",
    "        col = Variable(torch.LongTensor([np.long(col)]))\n",
    "\n",
    "        # Predict and calculate loss\n",
    "        prediction = model(row, col)\n",
    "        loss = loss_func(prediction, rating)\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4]),\n",
       " array([2, 3, 0, 1, 2, 3, 4, 1, 2, 4, 0, 1, 2, 3, 4, 0, 1, 2, 4]))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tensor(1.6375)\n",
      "4 tensor(-18.3524)\n",
      "2 tensor(29.9260)\n",
      "1 tensor(17.4291)\n",
      "1 tensor(27.9948)\n",
      "4 tensor(-160.5630)\n",
      "4 tensor(-32.1967)\n",
      "3 tensor(8.8649)\n",
      "4 tensor(3.2874)\n",
      "4 tensor(-1.5861)\n",
      "2 tensor(19.4142)\n",
      "1 tensor(-11.8924)\n",
      "4 tensor(-8.5185)\n",
      "3 tensor(44.9006)\n",
      "3 tensor(2.4343)\n",
      "2 tensor(-5.5661)\n",
      "3 tensor(3.1683)\n",
      "2 tensor(1.5059)\n",
      "4 tensor(3.6606)\n"
     ]
    }
   ],
   "source": [
    "rows, cols = ratings.nonzero()[0], ratings.nonzero()[1]\n",
    "\n",
    "for i in range(len(rows)):\n",
    "    row, col = rows[i], cols[i]\n",
    "    ri_tensor = torch.LongTensor([np.long(row)])\n",
    "    ci_tensor = torch.LongTensor([np.long(col)])\n",
    "    print(ratings[row][col], model(ri_tensor, ci_tensor).data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
